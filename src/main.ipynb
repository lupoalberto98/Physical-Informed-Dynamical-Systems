{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81ea2bf",
   "metadata": {},
   "source": [
    "# Machine Learning Dynamical Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install dependencies\n",
    "!pip install numpy matplotlib scipy\n",
    "!pip install tqdm plotly\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install optuna\n",
    "!pip install pytorch-lightning\n",
    "!pip install google\n",
    "!pip install odeintw\n",
    "!pip install torchdiffeq\n",
    "!pip install sdeint\n",
    "!pip install torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7fbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "%matplotlib inline\n",
    "\n",
    "# Basic import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import odeint\n",
    "from odeintw import odeintw\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.linalg import qr\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "# Pytorch import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Trainig with lighninig\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping \n",
    "from pytorch_lightning import Callback\n",
    "\n",
    "\n",
    "# Import models\n",
    "from models import LSTM,FFNet, ESN\n",
    "from TRANSFORMER import Transformer\n",
    "from CAE import ConvAE\n",
    "from CLSTMAE import ConvLSTMAE\n",
    "from CVAE import CVAE\n",
    "from ADALSTM import multi_rate_sampler, pretrain, AdaLSTM\n",
    "from pyESN import ESN\n",
    "#from Informer.model import InformerStack\n",
    "\n",
    "# dq dimension\n",
    "from dq_dimension import Box, DS, KL_div\n",
    "\n",
    "\n",
    "# Import plot functions\n",
    "from plot import plot_trajectory, compare_trajectories, plot_3Dtrajectory, poincare_plot, plot_powspec, plot_rec_trajectory, plot_params_distr, plot_3ddistr\n",
    "from plot import compare_R2scores\n",
    "\n",
    "# Import dataset\n",
    "from dataset import DynSysDataset, GenerateDynSystem\n",
    "\n",
    "# Import callbacks\n",
    "from callbacks import MetricsCallback\n",
    "\n",
    "# Import functions \n",
    "from utils import Lorenz63, Roessler76, Lorenz96, Eul, RK4, CeDLoss, Sampler, nKLDivLoss, R2Score, ENLoss\n",
    "\n",
    "# Import progress bars\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import plotly\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_param_importances, plot_contour\n",
    "\n",
    "\n",
    "#Import sys\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba17acf-f19d-4353-bcde-0d3859e67fd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example of attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd57a10-46e7-461d-8db2-054720099f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = 0.2\n",
    "w = 1\n",
    "def f_harm(u, t):\n",
    "    return u[1], -v*u[1]-w**2*u[0]\n",
    "\n",
    "def f_vp(u,t):\n",
    "    return u[1], (v-u[0]**2)*u[1]-w**2*u[0]\n",
    "\n",
    "u0 = [1,1]\n",
    "time = np.linspace(0,100,1000)\n",
    "us_harm = odeint(f_harm, u0, time)\n",
    "\n",
    "u0 = [0.5,0.5]\n",
    "us_vp = odeint(f_vp, u0, time)\n",
    "u0 = [1,1]\n",
    "us2 = odeint(f_vp, u0, time)\n",
    "\n",
    "# Lorenz63\n",
    "sigma=10\n",
    "rho=28,\n",
    "beta = 8./3.\n",
    "def f_l63(u, t):\n",
    "    return sigma*(u[1]-u[0]), u[0]*(rho-u[2])-u[1], u[0]*u[1]-beta*u[2]\n",
    "\n",
    "u0 = [1,1,1]\n",
    "time = np.linspace(0,40,4000)\n",
    "ldyn = odeint(f_l63, u0, time)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot(ldyn[1000:,0], ldyn[1000:,1], ldyn[1000:,2], c=\"black\")\n",
    "ax._axis3don = False\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"images/l63_attractor.png\")\n",
    "\n",
    "# Roessler 76\n",
    "a=0.37\n",
    "b=0.2\n",
    "c=5.7\n",
    "def f_roess(u,t):\n",
    "    return -u[1]-u[2], u[0]+a*u[1], b+u[2]*(u[0]-c)\n",
    "\n",
    "u0 = [1,1,1]\n",
    "time = np.linspace(0,100,10000)\n",
    "ldyn = odeint(f_roess, u0, time)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot(ldyn[1000:,0], ldyn[1000:,1], ldyn[1000:,2], c=\"black\")\n",
    "ax._axis3don = False\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"images/roess_attractor.png\")\n",
    "\n",
    "a=1.4\n",
    "b=0.3\n",
    "\n",
    "he = [[-0.1,0.1]]\n",
    "for i in range(100000):\n",
    "    x = 1+he[-1][1]-a*he[-1][0]**2\n",
    "    y = b*he[-1][0]\n",
    "    he.append([x,y])\n",
    "    \n",
    "he = np.array(he)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(he[1000:,0], he[1000:,1], c=\"black\", s=0.01)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# Inset axis\n",
    "axins = ax.inset_axes([0.1, 0.3, 0.4, 0.4])\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])\n",
    "axins.set_xlim(0.7, 1)\n",
    "axins.set_ylim(0.12, 0.18)\n",
    "axins.scatter(he[1000:,0], he[1000:,1], c=\"black\", s=0.01)\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "# Inset2\n",
    "axins2 = axins.inset_axes([0.6, 0.6, 0.4, 0.4])\n",
    "axins2.set_xticks([])\n",
    "axins2.set_yticks([])\n",
    "axins2.set_xlim(0.863, 0.9)\n",
    "axins2.set_ylim(0.14, 0.15)\n",
    "axins2.scatter(he[1000:,0], he[1000:,1], c=\"black\", s=0.01)\n",
    "axins.indicate_inset_zoom(axins2, edgecolor=\"black\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"images/henon_attractor.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fccdf2-0ad9-410f-9f66-92f882708c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bb34a-917c-4588-a359-4e593b945e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic map\n",
    "lm = []\n",
    "r_values = np.linspace(2.5,4,1000)\n",
    "for r in r_values:\n",
    "    lm_r = [0.3]\n",
    "    for i in range(1000):\n",
    "        x_new = r*lm_r[-1]*(1-lm_r[-1])\n",
    "        lm_r.append(x_new)\n",
    "\n",
    "    lm.append(lm_r)\n",
    "\n",
    "lm = np.array(lm)\n",
    "print(lm.shape, r_values.shape)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2,figsize=[10, 5])\n",
    "ax[0].set_xlabel(\"r\")\n",
    "ax[0].set_ylabel(\"$x_{\\infty}$\")\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "for xe, ye in zip(r_values, lm[:,100:]):\n",
    "    ax[0].scatter([xe] * len(ye), ye, s=0.001, c=\"black\")\n",
    "\n",
    "# Inset axis\n",
    "axins = ax[0].inset_axes([1.2, 0,1,1])\n",
    "axins.set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "axins.set_xlim(3.5, 4)\n",
    "axins.set_ylim(0, 1)\n",
    "for xe, ye in zip(r_values[667:], lm[667:,100:]):\n",
    "    ax[1].scatter([xe] * len(ye), ye, s=0.001, c=\"black\")\n",
    "    \n",
    "ax[0].indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "# Inset2\n",
    "plt.savefig(\"images/bifurcation_logistic.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af844311-9820-4a53-9322-7d2482ceb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feigenbaum attractor\n",
    "mu = 3.57\n",
    "lm_r = [0.3]\n",
    "for i in range(101000):\n",
    "    x_new = mu*lm_r[-1]*(1-lm_r[-1])\n",
    "    lm_r.append(x_new)\n",
    "\n",
    "lm_r = np.array(lm_r)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,1,figsize=[10, 5])\n",
    "ax.set_xlabel(\"$x_{\\infty}$\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "discard=1000\n",
    "ax.hist(lm_r[discard:], bins=1000, color=\"black\", density=True, range=([0,1]))\n",
    "\n",
    "# Inset2\n",
    "plt.savefig(\"images/feigenbaum_attractor.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016326-edc4-47b5-80e3-04fec29e514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379e13f-43d4-4eb0-8523-0d98c944a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pendolum\n",
    "v = 0.22\n",
    "T = 2.7\n",
    "\n",
    "def f_pend(u,t):\n",
    "    return T*np.sin(t)-np.sin(u[1])-v*u[0], u[0]\n",
    "\n",
    "u0 = [0,0]\n",
    "time = 1000000\n",
    "dt = 0.01\n",
    "time = np.linspace(0,time,int(time/dt))\n",
    "n = int(2*math.pi/dt)\n",
    "pend = odeint(f_pend, u0, time)\n",
    "pend = np.array(pend)\n",
    "pend[:,1] = pend[:,1]%(2*math.pi)-math.pi\n",
    "pend = pend[0::n]\n",
    "print(pend.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(pend[:,1], pend[:,0], c=\"black\", s=0.01)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#ax.spines['left'].set_visible(False)\n",
    "#ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"$d\\\\theta/dt$\")\n",
    "ax.set_xlabel(\"$\\\\theta$\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"images/pendolum_attractor.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fde7a-c6f2-4660-9eab-9d1711cbda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2dPhaseDiagram(us, us2=None, filename=None):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    arrow_fmt = dict(markersize=4, color='black', clip_on=False)\n",
    "    arrow_2 = dict(markersize=12, color='black', clip_on=False)\n",
    "    ax.plot(us[:-600,0], us[:-600,1],  c=\"black\")\n",
    "    ax.plot(us[-600:,0], us[-600:,1],  c=\"red\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.annotate(\"A\", (us[0,0]+0.05, us[0,1]))\n",
    "    ax.scatter(us[0,0], us[0,1], s=20,  c=\"black\" )\n",
    "    \n",
    "    if us2 is not None:\n",
    "        ax.scatter(us2[0,0], us2[0,1], s=20,  c=\"black\" )\n",
    "        ax.plot(us2[:-100,0], us2[:-100,1],  c=\"black\")\n",
    "        ax.annotate(\"B\", (us2[0,0]+0.1, us2[0,1]))\n",
    "        ax.plot(us2[-100:,0], us2[-100:,1],  c=\"red\")\n",
    "        \n",
    " \n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlabel('$x^{(1)}$', size=14, labelpad=-24, x=1.03)\n",
    "    ax.set_ylabel('$x^{(2)}$', size=14, labelpad=-21, y=1.02, rotation=0)\n",
    "\n",
    "    \n",
    "    ax.plot((1), (0), marker='>', transform=ax.get_yaxis_transform(), **arrow_fmt)\n",
    "    ax.plot((0), (1), marker='^', transform=ax.get_xaxis_transform(), **arrow_fmt)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "    return fig\n",
    "\n",
    "fig = plot_2dPhaseDiagram(us_harm, filename=\"images/phase_diagram_oscillator.png\")\n",
    "fig = plot_2dPhaseDiagram(us_vp, us2, filename=\"images/phase_diagram_vanderPol.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad68f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51027a35-7c9c-42b2-9a56-930a9b1317d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters and systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2416a7-bd32-4a3d-8f2b-c2c86d4382c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq_len:  501\n"
     ]
    }
   ],
   "source": [
    "### Parameters\n",
    "dt = 0.002\n",
    "train_steps = 100000 # 200 seconds\n",
    "val_steps = 10000 # 20 seconds\n",
    "test_steps = 100000 #100 seconds\n",
    "time_pred = 1 # inverse of first Lyapunov exponent usually\n",
    "seq_len = int(time_pred/dt)+1 # +1 because we get rid of one element during prediction, useful for convolutional nn and ff\n",
    "print(\"Seq_len: \", seq_len)\n",
    "feedforward_steps = 1\n",
    "discard = int(10/dt) # first ten seconds\n",
    "sigma = None # standard deviation\n",
    "include_time = False\n",
    "\n",
    "\n",
    "### Systems\n",
    "## Lorenz63\n",
    "true_params_l63 = np.array((28., 10., 8.0/3.0))\n",
    "true_params_l63 = torch.tensor(true_params_l63, dtype=torch.float32, requires_grad=False)\n",
    "l63 = Lorenz63(params=true_params_l63)\n",
    "l63.params.requires_grad = False\n",
    "\n",
    "## Lorenz96\n",
    "n_dim = 5\n",
    "np.random.seed(0)\n",
    "true_params_l96 = np.array((np.ones(n_dim), np.random.uniform(0.9, 1.1, n_dim), np.random.uniform(7.9, 8.1, n_dim)))\n",
    "true_params_l96 = torch.tensor(true_params_l96, dtype=torch.float32, requires_grad=False)\n",
    "l96 = Lorenz96(dim=n_dim, params=true_params_l96)\n",
    "l96.params.requires_grad = False\n",
    "\n",
    "\n",
    "## RÃ¶ssler\n",
    "true_params_r76 = (0.37, 0.2, 5.7)\n",
    "true_params_r76 = torch.tensor((0.37, 0.2, 5.7), dtype=torch.float32, requires_grad=False)\n",
    "r76 = Roessler76(params = true_params_r76)\n",
    "r76.params.requires_grad = False\n",
    "\n",
    "# Define system to use and generate data\n",
    "true_system = l63\n",
    "true_params = true_params_l63\n",
    "#true_system.args.requires_grad = False\n",
    "#print(true_system.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64deba8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validtion dataset\n",
    "state0 = torch.rand(true_system.dim)\n",
    "filename = \"datasets/val_\"+true_system.__class__.__name__+\"_steps\"+str(val_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "val_dataset, t_val = GenerateDynSystem(state0, true_system, dt, val_steps, discard, filename, sigma, include_time)()\n",
    "\n",
    "\n",
    "# Train dataset\n",
    "state0 = torch.rand(true_system.dim)\n",
    "filename = \"datasets/train_\"+true_system.__class__.__name__+\"_steps\"+str(train_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "train_dataset, t_train = GenerateDynSystem(state0, true_system, dt, train_steps, discard, filename, sigma, include_time)()\n",
    "\n",
    "\n",
    "# Test dataset\n",
    "state0 = train_dataset[-1]\n",
    "discard_test=0\n",
    "filename = \"datasets/test_\"+true_system.__class__.__name__+\"_steps\"+str(test_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "test_dataset, t_test = GenerateDynSystem(state0, true_system, dt, test_steps, discard_test, filename, sigma, include_time)()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6dad684-4922-4aa8-9f81-a9a9431c9ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100000\n",
      "Mean test dataset:  [ 1.5537462  1.5509158 23.52063  ]\n",
      "Std test dataset:  [7.770552 8.893026 8.668696]\n"
     ]
    }
   ],
   "source": [
    "### Dataloaders\n",
    "batch_size = 20\n",
    "train_filename = \"datasets/train_\"+true_system.__class__.__name__+\"_steps\"+str(train_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "\n",
    "train_states = DynSysDataset(train_filename, seq_len=seq_len, dt=dt, tau=1)\n",
    "t_train = train_states.time\n",
    "train_dataset = train_states.dataset\n",
    "train_dataloader = DataLoader(train_states, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "val_filename = \"datasets/val_\"+true_system.__class__.__name__+\"_steps\"+str(val_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "val_states = DynSysDataset(train_filename, seq_len=seq_len, dt=dt, tau=1)\n",
    "t_val = val_states.time\n",
    "val_dataset = val_states.dataset\n",
    "val_dataloader = DataLoader(val_states, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "test_filename = \"datasets/test_\"+true_system.__class__.__name__+\"_steps\"+str(test_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "test_states = DynSysDataset(test_filename, seq_len=seq_len, dt=dt, tau=1)\n",
    "t_test = test_states.time\n",
    "test_dataset = test_states.dataset\n",
    "test_dataloader = DataLoader(test_states, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "### Plot dataset\n",
    "# Train dataset\n",
    "#rk4 = RK4(dt, true_system)\n",
    "#eul = Eul(dt, true_system)\n",
    "#train_dataset = eul(train_dataset)\n",
    "name_dyn_data = \"images/dynamics_\"+true_system.__class__.__name__+\".png\"\n",
    "name_train_attractor = \"images/attractor_\"+true_system.__class__.__name__+\".png\"\n",
    "name_test_attractor = \"images/attractor_test_\"+true_system.__class__.__name__+\".png\"\n",
    "#train_dynamics = plot_trajectory(train_dataset, time=t_train, n_var=3, labels=[\"x\",\"y\",\"z\"], filename = name_dyn_data, prediction_steps=10000)\n",
    "#train_attractor = plot_3Dtrajectory(train_dataset, filename = name_train_attractor)\n",
    "#test_attractor = plot_3Dtrajectory(test_dataset, filename = name_test_attractor)\n",
    "print(test_dataset.shape[0], t_test.shape[0])\n",
    "\n",
    "# Statistics test dataset\n",
    "mean_test_dataset = np.mean(test_dataset.detach().cpu().numpy(), axis=0)\n",
    "std_test_dataset = np.std(test_dataset.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "print(\"Mean test dataset: \", mean_test_dataset)\n",
    "print(\"Std test dataset: \", std_test_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2e074-5f47-45d0-82d4-5f31f9af1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS module\n",
    "ds = DS(test_dataset.detach().cpu().numpy(), eta=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a522b7-7992-4d3d-bee4-373ad453639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_q dimension\n",
    "q=1\n",
    "d_q = ds.d_q(q=q, min_eps=1, max_eps=1.2, num_eps=10, plot=True)\n",
    "print(\"D_\"+str(q)+\" dimension: \", d_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5f560-7583-437f-9029-27824bbc0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyapunov exponents analysis\n",
    "discard = 150\n",
    "n_div = 4\n",
    "lles = ds.compute_lle(true_system, n_div, dt, discard)\n",
    "print(lles.shape)\n",
    "print(\"Lyapunov exponents (mean, std): \", ds.le, ds.le_std)\n",
    "\n",
    "# lyapunov dimension\n",
    "lyap_d = ds.lyap_d()\n",
    "print(\"Lyapunov dimension: \", lyap_d)\n",
    "\n",
    "# Distributions\n",
    "fig, _ = plot_params_distr(torch.tensor(lles), plot_stat=True, true_params=[0.905, 0,-14.5714],\n",
    "                           labels=[\"LLE1\", \"LLE2\", \"LLE3\"], bins=200, filename=None)\n",
    "\n",
    "lle1_attractor = plot_3Dtrajectory(test_dataset[0::n_div,:][discard:], color=lles[:,0])\n",
    "lle2_attractor = plot_3Dtrajectory(test_dataset[0::n_div,:][discard:], color=lles[:,1])\n",
    "lle3_attractor = plot_3Dtrajectory(test_dataset[0::n_div,:][discard:], color=lles[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb7ccd-2017-467a-a0b3-d13e84c88192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl divergence\n",
    "kl_div, pdf_p, pdf_q = KL_div(test_dataset.detach().cpu().numpy(), test_dataset.detach().cpu().numpy(), epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5189e7b-147a-43f1-93a4-c54ed37a4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kl_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa408f6-9aa7-4b52-ae74-1b6c58274857",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_p, pdf_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9b7ae-19f1-459c-8164-bb38f10353a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm \n",
    "\n",
    "\n",
    "def plot_pdf(box, filename=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    for i in range(box.int_sizes[0]):\n",
    "        for j in range(box.int_sizes[1]):\n",
    "            for k in range(box.int_sizes[2]):\n",
    "                indexes = [i,j,k]\n",
    "                center = box.get_center_cube(indexes)\n",
    "                ax.scatter(center[0], center[1], center[2], marker=\"s\", s=200, c=cm.Reds(box.pdf[i,j,k]))\n",
    "                print(cm.Reds(box.pdf[i,j,k]))\n",
    "plot_pdf(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83db0f6-b2b7-4555-b9e8-38f2b2009a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "645605bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db10b05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2bad2d-76bf-4a2c-b440-e49efc86e97b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2299037",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter optmization\n",
    "#Check if the GPU is available\n",
    "\n",
    "\n",
    "# Define annealing\n",
    "max_num_epochs = 2000\n",
    "initial_value = 5\n",
    "exp_decay = np.exp(-np.log(initial_value) / max_num_epochs * 6) # We compute the exponential decay in such a way the shape of the exploration profile does not depend on the number of iterations\n",
    "annealing = [initial_value * (exp_decay ** i) for i in range(max_num_epochs)]\n",
    "    \n",
    "# Define loss function\n",
    "loss_fn = PILoss(dt,field = L63_field(rho = 28.0, sigma = 10.0, beta = 8.0/3.0), annealing= [1]*max_num_epochs)\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define objects to be optimized\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log = True)\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 10,200)\n",
    "    layers_num = trial.suggest_int(\"layers_num\", 2,5)\n",
    "    drop_p = trial.suggest_float(\"dropout\", 0.0, 1.0)\n",
    "   \n",
    "    # Define network\n",
    "    input_size = 3\n",
    "    model = LSTM(input_size, hidden_units, layers_num, drop_p)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "        \n",
    "    # Train\n",
    "    max_num_epochs = 100\n",
    "    early_stopping = False\n",
    "    train_loss, val_loss = pi_train(model, device, train_dataloader, val_dataloader, loss_fn, optimizer, max_num_epochs, early_stopping)\n",
    "    \n",
    "    # Metric to be minimized is the last validation loss\n",
    "    return np.mean(val_loss[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a68691",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials= 20)\n",
    "study.best_params  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b62e05-1bc0-4137-b03b-b56975ca0250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Learning the dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73590a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n",
    "# Set seed and define network\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Check batch dimension\n",
    "print(next(iter(train_dataloader)).shape)\n",
    "use_pi_loss = False\n",
    "hidden_units = 100\n",
    "layers_num = 2\n",
    "l1 = 0.0\n",
    "net_pi = LSTM(input_size=true_system.dim, hidden_units=hidden_units, layers_num=layers_num, system=true_system, \n",
    "              true_system=true_system,drop_p=0.3, method_name=\"RK4\", use_pi_loss=use_pi_loss,\n",
    "             return_rnn=False, perturbation=None, bidirectional=False, train_out=True, l1=l1)\n",
    "\n",
    "print(net_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c39a40-e841-4452-95eb-c01ab76ca3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "state = batch[:,:-1,:]\n",
    "labels = batch[:,1:,:]\n",
    "next_state = net_pi(10,state)\n",
    "df = net_pi.method(state)\n",
    "df2 = net_pi.method.model(10,state)\n",
    "print(torch.mean((df2-next_state)**2))\n",
    "print(torch.mean((labels-df-state)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a950be-f100-48af-b9e0-800954ba7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"LSTM_dd_Lorenz63_ep2000_h100_ln2_sigmaNone.torch\")\n",
    "net_pi.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "net_pi.set_output(False)\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_pi, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3de6bc-8e1e-4aa6-8022-708e2463026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_system.params)\n",
    "print(system.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f7d8e-81e6-4b5e-96ad-e3d047e69f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Names for savings\n",
    "if use_pi_loss:\n",
    "    type=\"pi\"\n",
    "else:\n",
    "    type=\"dd\"\n",
    "\n",
    "root = net_pi.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_ep\"+str(len(metrics_callback.train_loss_log))+\"_h\"+str(hidden_units)+\"_ln\"+str(layers_num)+\"_sigma\"+str(sigma)+\"_l1\"+str(l1)\n",
    "#root = \"LSTM_pi_Lorenz63_ep2000_h100_ln2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_compare = \"compare_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "delay = 1\n",
    "name_poincare = \"poincare_delay\"+str(delay)+\"_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_le = \"le_\"+\"root\"+\".png\"\n",
    "folder = \"images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "ax.semilogy(metrics_callback.params_loss_log, label=\"Args loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "#fig.savefig(folder+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45bd76-9c28-4f3a-9e69-3488fddb7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n",
    "net_states = net_pi.predict(200, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab0f7b-8c47-49f7-860b-564ba1fac8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl divergence\n",
    "kl_div, _, _ = KL_div(net_states.detach().cpu().numpy(), test_dataset.detach().cpu().numpy(), epsilon=1.)\n",
    "print(kl_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb810d-46c1-49fb-83f0-7ea9671b8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statistics\n",
    "mean_nn = np.mean(net_states.detach().cpu().numpy(), axis=0)\n",
    "std_nn = np.std(net_states.detach().cpu().numpy(), axis=0)\n",
    "print(\"NN statistics: \", mean_nn, std_nn)\n",
    "print(\"Test dataset statistics: \", mean_test_dataset, std_test_dataset)\n",
    "# Wasserstein distance\n",
    "wass_dist = []\n",
    "for i in range(true_system.dim):\n",
    "    wass_dist.append(wasserstein_distance(test_dataset.detach().cpu().numpy()[:,i], net_states.detach().cpu().numpy()[:,i]))\n",
    "\n",
    "print(\"Wasserstein distances: \", wass_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90616f-56bc-40a5-bb57-ab8faec4cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 scores\n",
    "net_pi.set_output(True)\n",
    "time = 1\n",
    "r2_scores = compare_R2scores(net_pi, test_dataset, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201cb0d-8878-4040-8c5c-660ee2ef9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and colored attractor\n",
    "fig, statistics = plot_params_distr(torch.tensor(r2_scores), plot_stat=False, true_params=None, labels=None, bins=100, filename=None)\n",
    "r2_scores_mean_attractor = plot_3Dtrajectory(net_states[:-prediction_steps], color=np.mean(r2_scores, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb285a91-6492-4217-8caf-c48c296f0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute r2_score for different prediciton_steps\n",
    "prediction_steps = [10, 50, 100, 200, 500]\n",
    "mean = []\n",
    "std = []\n",
    "\n",
    "for steps in prediction_steps:\n",
    "    r2_scores = compare_R2scores(net_pi, test_dataset, prediction_steps=steps)\n",
    "    mean.append(np.mean(r2_scores, axis=0))\n",
    "    std.append(np.std(r2_scores, axis=0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae95bd-b129-4b52-8cc0-f7b5a9957afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot r2 scores\n",
    "mean = np.array(mean)\n",
    "std = np.array(std)\n",
    "print(mean)\n",
    "print(std)\n",
    "for i in range(true_system.dim):\n",
    "    plt.errorbar(prediction_steps[2:], mean[2:,i], yerr= std[:,i])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d85841",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "delay=50\n",
    "compare = compare_trajectories(net_states, test_dataset, time=t_test, n_var=3, filename=None, prediction_steps=2000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=None, color=None)\n",
    "print(net_states[1:, 0].size, net_states[:-1,0].size)\n",
    "# Poincare map\n",
    "poincare_plot(torch.tensor(test_dataset), delay=delay, filename=None, prediction_steps=10000)\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_pi.state_dict(),\"trained_models/\"+name_net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436647b3-1294-4ac2-a6e0-724bb7166cc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multi rate sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235e4b3-b3ec-48c0-9d63-a80773479145",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multi rate sampler\n",
    "num_lstm = 2\n",
    "tau = np.arange(1,num_lstm+1)\n",
    "length = [100]*num_lstm\n",
    "batch_size = 20\n",
    "mrs = multi_rate_sampler(tau, length, dt, batch_size=batch_size)\n",
    "\n",
    "# Dataloaders\n",
    "train_filename = \"datasets/train_\"+true_system.__class__.__name__+\"_steps\"+str(train_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "train_mrs_list = mrs.divide_dataloader(train_filename, num_workers=0, shuffle=True)\n",
    "val_filename = \"datasets/val_\"+true_system.__class__.__name__+\"_steps\"+str(val_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".csv\"\n",
    "val_mrs_list = mrs.divide_dataloader(val_filename, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "# Stack lstm\n",
    "use_pi_loss = True\n",
    "hidden_units = 100\n",
    "layers_num = 2\n",
    "stack_lstm = {}\n",
    "torch.manual_seed(0)\n",
    "for i in range(num_lstm):\n",
    "    model = LSTM(input_size=true_system.dim, hidden_units=hidden_units, layers_num=layers_num, system=true_system, \n",
    "                 true_system=true_system, drop_p=0.3, method_name=\"RK4\", use_pi_loss=use_pi_loss, return_rnn=False, perturbation=None, bidirectional=False, train_out=True)\n",
    "    stack_lstm[\"LSTM\"+str(i+1)] = model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8ec4a-b986-43cf-9a6f-552f9659e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "train_loss_logs, val_loss_logs = pretrain(stack_lstm, train_mrs_list, val_mrs_list, patience=20, max_num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf389f63-b7b9-4d25-a706-e16ed6b3fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot pretrain losses\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].set_title(\"Training loss\")\n",
    "ax[0].set_xlabel(\"Epoch num\")\n",
    "ax[1].set_title(\"Validation loss\")\n",
    "ax[1].set_xlabel(\"Epoch num\")\n",
    "\n",
    "for i in range(num_lstm):\n",
    "    ax[0].semilogy(train_loss_logs[i], label=\"LSTM \"+str(i+1))\n",
    "    ax[1].semilogy(val_loss_logs[i], label=\"LSTM \"+str(i+1))\n",
    "    \n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "#fig.savefig(folder+name_pretrain_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8e52d-c1a7-4c8f-bc7d-ca8015b7ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pretrain models \n",
    "torch.save(stack_lstm,\"trained_models/pretrain.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4960868-43f3-4e71-8f05-bf95ae5fa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n",
    "# Define adaptive LSTM\n",
    "torch.manual_seed(0)\n",
    "ada_lstm = AdaLSTM(stack_lstm, mrs, true_system.dim, hidden_units, lr=0.001, return_rnn=False)\n",
    "print(ada_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac48f2d-c02b-42cd-86b8-52eb4e3cf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_lstm.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe1a1d-ad56-40f5-a3bb-f686c33ab553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "root = \"AdaLSTM_pi__numlstm5_Lorenz63_ep296_h100_ln2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "state_dict = torch.load(\"trained_models/\"+name_net)\n",
    "ada_lstm.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64888919-4fd7-488c-9cbe-af361aa3b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=ada_lstm, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e764c-f732-403b-98ef-729ee1800219",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Names for savings\n",
    "if use_pi_loss:\n",
    "    type=\"pi\"\n",
    "else:\n",
    "    type=\"dd\"\n",
    "    \n",
    "#root = ada_lstm.__class__.__name__+\"_\"+type+\"_\"+\"_numlstm\"+str(num_lstm)+\"_\"+true_system.__class__.__name__+\"_ep\"+str(len(metrics_callback.train_loss_log))+\"_h\"+str(hidden_units)+\"_ln\"+str(layers_num)+\"_sigma\"+str(sigma)\n",
    "#root = \"AdaLSTM_numlstm3_Lorenz63_ep148_h100_ln2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_pretrain_losses = \"pretrain_loss_\"+root+\".png\"\n",
    "name_compare = \"compare_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_le = \"le_\"+\"root\"+\".png\"\n",
    "folder = \"images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f069d-e183-4c5d-8982-ec378627eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "#fig.savefig(folder+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30907551-c2b3-406e-8238-b735f4762732",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n",
    "def gen_mrs_trajectory(net, x0, num_lstm, prediction_steps = 1000):\n",
    "    \" Generate a trajectory of prediction_steps lenght starting from test_dataset[0]. Return np.array\"\n",
    "    x = [x0.unsqueeze(0).unsqueeze(0)]*num_lstm\n",
    "    rnn_state = [(torch.zeros(net.layers_num_list[i], 1, net.hidden_units), torch.zeros(net.layers_num_list[i], 1, net.hidden_units)) for i in range(num_lstm)]\n",
    "    print(rnn_state[0][1].shape)\n",
    "    print(x[0].shape)\n",
    "    net_states = []\n",
    "    net.eval()\n",
    "   \n",
    "    for i in range(prediction_steps):\n",
    "        with torch.no_grad():\n",
    "            # Forward past\n",
    "            x, rnn_state = net(i, x, rnn_state)\n",
    "            net_states.append(x.squeeze().numpy())\n",
    "            x = [x.unsqueeze(1)]*num_lstm\n",
    "\n",
    "    return torch.tensor(net_states)\n",
    "\n",
    "\n",
    "ada_lstm.set_return_rnn(True)\n",
    "net_states = gen_mrs_trajectory(ada_lstm.cpu(), test_dataset[0], num_lstm, prediction_steps=20000)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080a325-d760-4775-8fb8-1813f6ac59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bc39c-9143-4d68-bf25-c3bc84632e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ada_lstm.attention.data.detach().cpu().numpy())\n",
    "print(ada_lstm.attention.data.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b22a80-c4bf-4608-8df7-27a36e910ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "compare = compare_trajectories(net_states, test_dataset, time=t_val, n_var=3, filename=None, prediction_steps=2000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=None, color=None)\n",
    "print(net_states[1:, 0].size, net_states[:-1,0].size)\n",
    "# Poincare map\n",
    "poincare_plot(net_states, torch.tensor(test_dataset), filename=None, prediction_steps=10000)\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970d277-36fb-4e4b-82c0-5b53dac61718",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(ada_lstm.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2f463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Autograd time differantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0abc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "state0 = [1.0, 1.0, 1.0]\n",
    "include_time = True\n",
    "train_states = DynSysDataset(state0, f, dt, steps, seq_len, discard, include_time=include_time)\n",
    "t_train = train_states.time\n",
    "train_dataset = train_states.dataset\n",
    "train_dataloader = DataLoader(train_states, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "max_num_epochs = 2000\n",
    "c = 0.01\n",
    "d = 0.5\n",
    "\n",
    "loss_fn = EuDLoss(dt, field = L63_field(rho = 28.0,\n",
    "                sigma = 10.0, beta = 8.0/3.0), include_time=include_time)\n",
    "\n",
    "input_size = 4 if include_time else 3\n",
    "params = {\n",
    "    \"input_size\" : 4,\n",
    "    \"hidden_units\" : 100,\n",
    "    \"layers_num\" : 2,\n",
    "    \"drop_p\" : 0.3,\n",
    "    \"loss_fn\" : loss_fn,\n",
    "    \"lr\" : 0.01,\n",
    "    \"feedforward_steps\" : 1,\n",
    "    \"curriculum_learning\" : None,\n",
    "}\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n",
    "# Set seed and define network\n",
    "torch.manual_seed(0)\n",
    "net_pi = LSTM(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trye torch.autograd\n",
    "batch = next(iter(train_dataloader))\n",
    "net_pi.set_output(False)\n",
    "out = net_pi(batch)\n",
    "# Reshape\n",
    "batch = torch.reshape(batch[0,:100], (100,4))\n",
    "out = torch.reshape(out[0,:100], (100,4))\n",
    "\n",
    "grad_outputs = torch.tensor([[0.,0.,0.,1.]]*100)\n",
    "print(grad_outputs.shape)\n",
    "\n",
    "grad = torch.autograd.grad(out[0], batch[0], grad_outputs=grad_outputs[0], is_grads_batched=False)\n",
    "print(grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edc1f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8fe37-afbb-4887-97b0-38079c8eb62c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e93e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros(): argument 'size' must be tuple of ints, but found element of type tuple at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Set seed and network\u001b[39;00m\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m net_tf \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_encoder_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_feedforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_system\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtrue_system\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_system\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReLU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRK4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pi_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pi_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mapply_src_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_src_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_tgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_tgt_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep Learning/MSc thesis/Physical-Informed-Dynamical-Systems/src/TRANSFORMER.py:78\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, system, true_system, dropout, activation, lr, l1, dt, method_name, use_pi_loss, apply_src_mask, apply_tgt_mask)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(utils, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod_name)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Positional encoder\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mPositionalEncoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Transoformer\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer(d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnhead, num_encoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_encoder_layers, \n\u001b[1;32m     83\u001b[0m                                   num_decoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_decoder_layers, dim_feedforward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_feedforward, \n\u001b[1;32m     84\u001b[0m                                   dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Deep Learning/MSc thesis/Physical-Informed-Dynamical-Systems/src/TRANSFORMER.py:23\u001b[0m, in \u001b[0;36mPositionalEncoding.__init__\u001b[0;34m(self, dim_model, dropout_p, max_len)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(dim_model)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Encoding - From formula\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m pos_encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m positions_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, max_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# 0, 1, 2, 3, 4, 5\u001b[39;00m\n\u001b[1;32m     25\u001b[0m division_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, dim_model, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m10000.0\u001b[39m)) \u001b[38;5;241m/\u001b[39m dim_model) \u001b[38;5;66;03m# 1000^(2i/dim_model)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros(): argument 'size' must be tuple of ints, but found element of type tuple at pos 2"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "d_model = 3\n",
    "nhead = 3\n",
    "num_encoder_layers = 6,\n",
    "num_decoder_layers = 6,\n",
    "dim_feedforward = 360\n",
    "dropout = 0.3\n",
    "l1 = 0\n",
    "use_pi_loss = True\n",
    "apply_src_mask = False\n",
    "apply_tgt_mask = True,\n",
    "\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n",
    "# Set seed and network\n",
    "torch.manual_seed(0)\n",
    "net_tf = Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, system=true_system, \n",
    "                     true_system=true_system, dropout=dropout, \n",
    "                     activation=\"ReLU\", lr=0.001, l1=l1, dt=dt, method_name=\"RK4\", use_pi_loss=use_pi_loss, \n",
    "                     apply_src_mask=apply_src_mask, apply_tgt_mask=apply_tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trainig\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_tf, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "plt.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "plt.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/loss_transformer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "net_dict = { \"state\" : net_pi.state_dict(),\n",
    "            \"parameters\" : params}\n",
    "# Save the state dict to a file\n",
    "torch.save(net_dict,\"trained_models/Transformer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919b56c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Informer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "loss_fn = EuDLoss(dt, field = L63_field(rho = 28.0, sigma = 10.0, beta = 8.0/3.0))\n",
    "\n",
    "# Define the network\n",
    "torch.manual_seed(0)\n",
    "net_inf = InformerStack(enc_in = 3, dec_in = 3, c_out = 3, seq_len = 499, label_len = 499, out_len = 1, \n",
    "                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n",
    "                dropout=0.3, lr=0.001, loss_fn=loss_fn, attn='prob', embed='fixed', freq='h', activation='gelu')\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df033a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_inf, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "plt.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "plt.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/loss_informer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "net_dict = { \"state\" : net_pi.state_dict(),\n",
    "            \"parameters\" : params}\n",
    "# Save the state dict to a file\n",
    "torch.save(net_dict,\"trained_models/Informer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093858-4040-4699-86df-116c9c762a93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2f2fb-e4fc-4477-89e8-199479e28fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define loss function\n",
    "loss_fn = nn.MSELoss() \n",
    "max_num_epochs = 1000\n",
    "\n",
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "net_ae = ConvEncoder(in_channels=(1,16), out_channels=(16,32), kernel_sizes=((100,3), (100,1)), \n",
    "           padding=(0,0),  encoded_space_dim=2, act=nn.ReLU, drop_p=0.3, seq_len=seq_len,\n",
    "                loss_fn=loss_fn, lr=0.001)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 1000, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aad4db-11bf-4dea-ae1b-658166fac37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=max_num_epochs, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_tf, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e91f1a-54ed-4742-86a3-a0d446710886",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "plt.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "plt.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/loss_autoencoder.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc293eab-1af7-4fff-8450-f263151b38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed trajectory\n",
    "enc, rec = net_ae(val_states.data)\n",
    "rec = rec.detach().numpy()\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "for i in range(len(rec)):\n",
    "    ax.plot(rec[i,0,:,0], rec[i,0,:,1], rec[i,0,:,2], c=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132433f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1ec2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a01c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "encoded_space_dim = 20\n",
    "enc_space_reg = None\n",
    "beta = 1.0\n",
    "gamma = 1\n",
    "lr = 0.001\n",
    "lr_scheduler_name = \"ExponentialLR\" \n",
    "\n",
    "net_ae = ConvAE(in_channels=(1,16,16), out_channels=(16,16,32), kernel_sizes=((5,3), (5,1), (5,1)), \n",
    "           padding=(0,0,0),  encoded_space_dim=encoded_space_dim, act=nn.ReLU, drop_p=0.3, seq_len=seq_len, feedforward_steps=1,\n",
    "                lr=lr, dt=dt, system_name=\"Lorenz63\",system_dim=3,num_param=len(true_params), enc_space_reg=enc_space_reg,\n",
    "                beta=beta, lr_scheduler_name=lr_scheduler_name, gamma=gamma)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9534b-9d20-4d0c-80be-2cf2eac5dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+name_net)\n",
    "net_ae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e178e-7ad4-4ea1-be5d-fc4d31de7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_ae, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af307b-0943-4f06-a055-91a438c08b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define saving names\n",
    "if enc_space_reg is not None:\n",
    "    type=\"reg\"\n",
    "else:\n",
    "    type=\"unreg\"\n",
    "    \n",
    "root = net_ae.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_\"+str(len(metrics_callback.train_loss_log))+\"_es\"+str(encoded_space_dim)+\"_sigma\"+str(sigma)+\"_\"+lr_scheduler_name+str(gamma)\n",
    "root = \"ConvAE_reg_Lorenz63_1500_es10_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_rec = \"rec_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_hist = \"hist_\"+root+\".png\"\n",
    "name_distr = \"distr_\"+root+\".png\"\n",
    "\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c730f1f-2a79-479d-9949-9e4672876e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "if enc_space_reg is not None:\n",
    "    ax.semilogy(metrics_callback.train_reg_log, label=\"Train reg loss\")\n",
    "    ax.semilogy(metrics_callback.val_reg_log, label=\"Validation reg loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "#fig.savefig(\"images/\"+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44f69c-ed4a-4346-9e9b-8115c74c92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "net_states = net_ae.predict(time=200, inputs=test_dataset.to(device), input_is_looped=False)\n",
    "print(net_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089887ac-7887-494e-ae6c-7babb305a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "delay=50\n",
    "compare = compare_trajectories(net_states, test_dataset, time=t_test, n_var=3, filename=None, prediction_steps=5000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=None, color=None)\n",
    "print(net_states[1:, 0].size, net_states[:-1,0].size)\n",
    "# Poincare map\n",
    "poincare_plot(net_states, true_states=torch.tensor(test_dataset), delay=delay, filename=None, prediction_steps=5000)\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ba998-0a03-4e6c-b181-f6ba3d64e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 scores\n",
    "r2_scores = compare_R2scores(net_ae, test_dataset, time=1.002)\n",
    "mean = np.mean(r2_scores, axis=0)\n",
    "std = np.std(r2_scores, axis=0)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42850315-70d7-4875-9586-625206b89f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed traejctory\n",
    "net_ae.eval()\n",
    "enc, rec = net_ae(0, test_states.data.unsqueeze(1))\n",
    "print(enc.shape)\n",
    "\n",
    "plot_rec_trajectory(rec, filename=None)\n",
    "# Plot learned parameters distribution\n",
    "fig1, statistics= plot_params_distr(enc[:, 0:3], true_params=true_params, bins=20, filename=None)\n",
    "print(statistics)\n",
    "fig2 = plot_3ddistr(enc, true_params, indeces=[0,1,2],filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863562a-b669-4137-8cc8-cff26b7e314a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8fd1a-931c-4014-9c18-a6b160826abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_ae.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b479236-74d2-4259-8a65-4d2f9a49d3b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional LSTM autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff3027-3440-4e59-9dab-b98d2449b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "encoded_space_dim = 10\n",
    "enc_space_reg = \"PI\" # method to compute derivative, if None no regularization applied\n",
    "bd = True # bidirectionality\n",
    "lstm_hu = 100 # hidden units of lstm layers\n",
    "ln = 2 # number of layers of lstm\n",
    "beta= 1.0\n",
    "gamma = 0.99\n",
    "lr = 0.01\n",
    "lr_scheduler_name = \"ExponentialLR\" \n",
    "\n",
    "net_lstmae = ConvLSTMAE(in_channels=(1,16,16), out_channels=(16,16,32), kernel_sizes=((5,3), (5,1), (5,1)), \n",
    "           padding=(0,0,0),  encoded_space_dim=encoded_space_dim, lstm_hidden_units=lstm_hu, bidirectional=bd, layers_num=ln, act=nn.ReLU, drop_p=0.3, seq_len=seq_len, feedforward_steps=1,\n",
    "                lr=lr, dt=dt, system_name=\"Lorenz63\",system_dim=3,num_param=len(true_params), enc_space_reg=enc_space_reg,\n",
    "                       beta=beta, lr_scheduler_name=lr_scheduler_name, gamma=gamma)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 20, mode=\"min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999abaf-d330-401e-bf3a-55378a418899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"ConvLSTMAE_reg_Lorenz63_2500_es10_hu100_nl2_sigmaNone.torch\")\n",
    "net_lstmae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc8e20-2d14-4289-a851-510eb0023bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_lstmae, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da0f58f-26c2-4008-a754-0e23b5135fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define saving names\n",
    "if enc_space_reg is not None:\n",
    "    type=\"reg\"\n",
    "else:\n",
    "    type=\"unreg\"\n",
    "    \n",
    "    \n",
    "root = net_lstmae.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_\"+str(len(metrics_callback.train_loss_log))+\"_es\"+str(encoded_space_dim)+\"_hu\"+str(lstm_hu)+\"_nl\"+str(ln)+\"_sigma\"+str(sigma)+\"_\"+lr_scheduler_name+str(gamma)+\"_beta\"+str(beta)\n",
    "#root = \"ConvLSTMAE_reg_Lorenz63_2500_es10_hu100_nl2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_rec = \"rec_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_hist = \"hist_\"+root+\".png\"\n",
    "name_distr = \"distr_\"+root+\".png\"\n",
    "\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e823e3f-c764-453c-8538-aff41f421289",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "if enc_space_reg is not None:\n",
    "    ax.semilogy(metrics_callback.train_reg_log, label=\"Train reg loss\")\n",
    "    ax.semilogy(metrics_callback.val_reg_log, label=\"Validation reg loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"images/\"+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c12d4-f84e-4e6f-be51-30b67be22289",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed traejctory\n",
    "net_lstmae.eval()\n",
    "enc, rec = net_lstmae(test_states.data)\n",
    "print(enc.shape)\n",
    "print(rec.shape)\n",
    "plot_rec_trajectory(rec, filename=\"images/\"+name_rec)\n",
    "# Plot learned parameters distribution\n",
    "fig1, statistics= plot_params_distr(enc, true_params, bins=20, filename=\"images/\"+name_hist)\n",
    "print(statistics)\n",
    "fig2 = plot_3ddistr(enc, true_params, indeces=[0,1,2],filename=\"images/\"+name_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db869440-15b8-415f-b562-a4594f323457",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n",
    "net_lstmae.eval()\n",
    "epsilon = 1\n",
    "new_enc = enc.unsqueeze(1).repeat(1,101,1) \n",
    "noise = torch.randn_like(new_enc)*epsilon\n",
    "perturbed = new_enc + noise\n",
    "perturbed = torch.tensor([0,0,0,0,0,0,0,0,0,0], dtype=torch.float32).unsqueeze(0).unsqueeze(0).repeat(990,101,1)\n",
    "perturbed, rnn = net_lstmae.lstm(perturbed)\n",
    "perturbed = net_lstmae.out(perturbed)\n",
    "\n",
    "plot_rec_trajectory(perturbed.unsqueeze(1))\n",
    "print(perturbed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e70470-0895-4c53-90ab-45f96a8d18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_lstmae.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854016ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034af7b6-786c-460c-bfe1-d6fcdc2db326",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "encoded_space_dim = 10\n",
    "enc_space_reg = \"PI\"\n",
    "beta = 1.\n",
    "net_vae = CVAE(in_channels=(1,16,16), out_channels=(16,16,32), kernel_sizes=((5,3), (5,1), (5,1)), \n",
    "           padding=(0,0,0),  encoded_space_dim=encoded_space_dim, act=nn.ReLU, drop_p=0.3, seq_len=seq_len, feedforward_steps=1,\n",
    "                lr=0.001, dt=0.01, system_name=\"Lorenz63\",system_dim=3,num_param=len(true_params), enc_space_reg=enc_space_reg,\n",
    "                beta=beta)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 1000, mode=\"min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43387cc-c44b-40d1-8c03-7a6b8c86c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"CVAE_reg_Lorenz63_1000_es10_sigma5.0.torch\")\n",
    "net_vae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363456a-e094-430c-a8b0-a1c705f270bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device \n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch.shape)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_vae, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28a7c7-688e-4004-a652-b1531e092c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define saving names\n",
    "if enc_space_reg is not None:\n",
    "    type=\"reg\"\n",
    "else:\n",
    "    type=\"unreg\"\n",
    "    \n",
    "root = net_vae.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_\"+str(len(metrics_callback.train_loss_log))+\"_es\"+str(encoded_space_dim)+\"_sigma\"+str(sigma)\n",
    "#root = \"CVAE_reg_Lorenz63_1000_es10_sigma5.0\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_rec = \"rec_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_hist = \"hist_\"+root+\".png\"\n",
    "name_noise = \"noise_\"+root+\".png\"\n",
    "name_distr = \"distr_\"+root+\".png\"\n",
    "\n",
    "\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52643d-d729-4341-90a7-55c6ab94e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "if enc_space_reg is not None:\n",
    "    ax.semilogy(metrics_callback.train_reg_log, label=\"Train reg loss\")\n",
    "    ax.semilogy(metrics_callback.val_reg_log, label=\"Validation reg loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"images/\"+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a68dd4-586a-49e7-800d-4e83fc3953dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed traejctory\n",
    "net_vae.eval()\n",
    "enc, mean, logvar, indeces_1, indeces_2, indeces_3 = net_vae.encoder(test_states.data)\n",
    "noise = Sampler()(mean, logvar)\n",
    "rec = net_vae.decoder(enc, noise, indeces_1, indeces_2, indeces_3)\n",
    "print(enc.shape)\n",
    "print(mean.shape, logvar.shape)\n",
    "#print(noise)\n",
    "plot_rec_trajectory(rec, filename=\"images/\"+name_rec)\n",
    "# Plot learned parameters distribution\n",
    "fig1, statistics= plot_params_distr(enc, true_params, bins=20, filename=\"images/\"+name_hist)\n",
    "fig2, statistics_noise= plot_params_distr(torch.cat((mean, logvar), dim=-1), torch.tensor((0,0), dtype=torch.float32, requires_grad=False), bins=20, filename=\"images/\"+name_noise)\n",
    "print(statistics)\n",
    "fig3 = plot_3ddistr(enc, true_params, indeces=[0,1,2],filename=\"images/\"+name_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69edac5-1a15-489a-a9d3-507957044088",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12484781-4e60-42e6-b0c8-264d562f35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_vae.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bba6a-0f6e-46b8-8039-f16843419235",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reservoir Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f461579",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reservoir network\n",
    "np.random.seed(0)\n",
    "n_reservoir = 200\n",
    "sparsity = 0.95\n",
    "erdos_graph = True\n",
    "use_pi_loss = True\n",
    "spectral_radius = 1.2\n",
    "noise = 0.1\n",
    "net_esn = ESN(n_inputs = 3, system=true_system, n_outputs = 3, sparsity=sparsity, erdos_graph=erdos_graph, n_reservoir=n_reservoir, \n",
    "              timestep=dt, spectral_radius=spectral_radius, noise=noise, extended_states=True, use_pi_loss=use_pi_loss)\n",
    "\n",
    "# Training\n",
    "pred, training_rmse, transient = net_esn.fit(train_dataset[:-1,:].detach().numpy(), train_dataset[1:,:].detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf099cb-0cae-4b3b-915a-407c6d2861af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "net_states = net_esn.predict(200,test_dataset, continuation=False)\n",
    "\n",
    "print(\"Training rmse: %d\" %training_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253f865-87bc-45cc-96b4-48e7744624ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Names for savings\n",
    "if use_pi_loss:\n",
    "    type=\"pi\"\n",
    "else:\n",
    "    type=\"dd\"\n",
    "\n",
    "root = net_esn.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_rnodes\"+str(n_reservoir)+\"_eg\"+str(erdos_graph)+\"_spars\"+str(sparsity)+\"_sr\"+str(spectral_radius)+\"_noise\"+str(noise)+\"_sigma\"+str(sigma)\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_compare = \"compare_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "delay = 50\n",
    "name_poincare = \"poincare_delay\"+str(delay)+\"_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_le = \"le_\"+\"root\"+\".png\"\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17795e7d-0d9f-4b72-9187-75ed1ef4126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "delay=50\n",
    "compare = compare_trajectories(net_states, test_dataset, time=t_test, n_var=3, filename=None, prediction_steps=20000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=None, color=None)\n",
    "# Poincare map\n",
    "poincare_plot(net_states, delay=delay, true_states=torch.tensor(test_dataset), filename=None, prediction_steps=10000)\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f644e-2563-4cbf-9d98-2b20963c4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statistics\n",
    "mean_nn = np.mean(net_states.detach().cpu().numpy(), axis=0)\n",
    "std_nn = np.std(net_states.detach().cpu().numpy(), axis=0)\n",
    "print(\"NN statistics: \", mean_nn, std_nn)\n",
    "print(\"Test dataset statistics: \", mean_test_dataset, std_test_dataset)\n",
    "# Wasserstein distance\n",
    "wass_dist = []\n",
    "for i in range(true_system.dim):\n",
    "    wass_dist.append(wasserstein_distance(test_dataset.detach().cpu().numpy()[:,i], net_states[:,i].detach().cpu().numpy()))\n",
    "\n",
    "print(\"Wasserstein distances: \", wass_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329d8d9-48c3-4582-9cb0-bd235af7ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 scores\n",
    "time = 0.1\n",
    "r2_scores = compare_R2scores(net_esn, test_dataset, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817b7a1-30b6-4877-ba26-418c58623a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and colored attractor\n",
    "prediction_steps = int(time/dt)\n",
    "print(min(r2_scores[:,2]))\n",
    "mean = np.mean(r2_scores, axis=0)\n",
    "std = np.std(r2_scores, axis=0)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Std: \", std)\n",
    "fig, statistics = plot_params_distr(torch.tensor(r2_scores), plot_stat=False, true_params=None, labels=None, bins=100, filename=None, range=([0,1]))\n",
    "r2_scores_mean_attractor = plot_3Dtrajectory(net_states[:-prediction_steps], color=np.mean(r2_scores, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbcc772-6a99-4a6c-a562-d0adb06b5edd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FeedForward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba1ddd-913d-4495-aa44-93fbe927803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 20, mode=\"min\")\n",
    "\n",
    "# Define network\n",
    "n_inputs = true_system.dim\n",
    "n_outputs = true_system.dim\n",
    "num_h_layers = 3\n",
    "neurons = 100\n",
    "hidden_layers = [100]*num_h_layers\n",
    "drop_p = 0.1\n",
    "use_pi_loss = True\n",
    "torch.manual_seed(0)\n",
    "net_ff = FFNet(seq_len, n_inputs, n_outputs, hidden_layers, system=true_system, true_system=true_system, drop_p=drop_p, lr=0.001, dt=dt, \n",
    "          method_name=\"RK4\", activation=\"ReLU\", use_pi_loss=use_pi_loss, l1=0.0)\n",
    "print(net_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce9967-e2a7-484a-94a0-05c9a7400626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+name_net)\n",
    "net_ff.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab2d49-dfa7-49f3-a1bb-313ebada76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "trainer = pl.Trainer(max_epochs=500, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_ff, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c3374-a86c-4d26-9c3c-7d217e286766",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Names for savings\n",
    "if use_pi_loss:\n",
    "    type=\"pi\"\n",
    "else:\n",
    "    type=\"dd\"\n",
    "\n",
    "root = net_ff.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_ep\"+str(len(metrics_callback.train_loss_log))+\"_h\"+str(num_h_layers)+\"_ns\"+str(neurons)+\"_sigma\"+str(sigma)\n",
    "root = \"FFNet_pi_Lorenz63_ep21_h3_ns100_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_compare = \"compare_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "delay = 50\n",
    "name_poincare = \"poincare_delay\"+str(delay)+\"_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_le = \"le_\"+\"root\"+\".png\"\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b189f-c4c8-446f-9cab-a5c846f24169",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "#ax.semilogy(metrics_callback.params_loss_log, label=\"Args loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "#fig.savefig(folder+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce2b87-f332-4bbf-9b6f-3138f7fc6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "net_states = net_ff.predict(200, test_dataset.to(device), input_is_looped=False)\n",
    "print(net_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c80b96-1951-4ff3-a488-d831daa285dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.flatten(test_dataset[:seq_len-1,:]).unsqueeze(0)\n",
    "for i in range(100):\n",
    "    state = net_ff(0,state)\n",
    "    print(state[0,-3::].detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14cfbff-95aa-4e2e-a97d-b3e301e195f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statistics\n",
    "mean_nn = np.mean(net_states.detach().cpu().numpy(), axis=0)\n",
    "std_nn = np.std(net_states.detach().cpu().numpy(), axis=0)\n",
    "print(\"NN statistics: \", mean_nn, std_nn)\n",
    "print(\"Test dataset statistics: \", mean_test_dataset, std_test_dataset)\n",
    "# Wasserstein distance\n",
    "wass_dist = []\n",
    "for i in range(true_system.dim):\n",
    "    wass_dist.append(wasserstein_distance(test_dataset.detach().cpu().numpy()[:,i], net_states.detach().cpu().numpy()[:,i]))\n",
    "\n",
    "print(\"Wasserstein distances: \", wass_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc64b5-ef1a-498a-b856-d45abcee5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 scores\n",
    "r2_scores = compare_R2scores(net_ff, test_dataset, time=1.002)\n",
    "mean = np.mean(r2_scores, axis=0)\n",
    "std = np.std(r2_scores, axis=0)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf2a93-6f15-43d1-9f5f-7536ded72bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and colored attractor\n",
    "\n",
    "fig, statistics = plot_params_distr(torch.tensor(r2_scores), plot_stat=False, true_params=None, labels=None, bins=100, filename=None)\n",
    "r2_scores_mean_a1 = plot_3Dtrajectory(test_dataset[:-seq_len], color=r2_scores[:,0])\n",
    "r2_scores_mean_a2 = plot_3Dtrajectory(test_dataset[:-seq_len], color=r2_scores[:,0])\n",
    "r2_scores_mean_a3 = plot_3Dtrajectory(test_dataset[:-seq_len], color=r2_scores[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa07d3-1a85-4017-907d-382d71ce7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "delay=50\n",
    "compare = compare_trajectories(net_states, test_dataset, time=t_test, n_var=3, filename=None, prediction_steps=10000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=None, color=None)\n",
    "print(net_states[1:, 0].size, net_states[:-1,0].size)\n",
    "# Poincare map\n",
    "poincare_plot(net_states, true_states=torch.tensor(test_dataset), delay=delay, filename=None, prediction_steps=5000)\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af3161-5e60-440c-a73d-be1318cc70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_ff.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64a7c6-eafe-4763-a9cc-c3900499d20f",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b985c86-d8eb-422e-8cc8-19a15b718a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b5efd6-7e92-4268-86be-ab14d7df1914",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unsupervised lle computation (sperimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f213a-2df5-47a9-be7f-76dbfaf9c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset generation\n",
    "\n",
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8.0 / 3.0\n",
    "dt = 0.01\n",
    "\n",
    "eps = 0.01 # Perturbation\n",
    "len_seq = 5 # Length of the pertubed sequence\n",
    "t = np.arange(0.0, dt*len_seq, dt) # Time array\n",
    "\n",
    "# Add pertubation dimension and dynamics dimension\n",
    "print(states_dataset.shape) \n",
    "pd = np.expand_dims(states_dataset, axis=1)\n",
    "pd = np.expand_dims(pd, axis=1)\n",
    "perturbed_dataset = np.concatenate((pd, pd), axis=2)\n",
    "perturbed_dataset = np.concatenate((perturbed_dataset, pd), axis=2)\n",
    "print(perturbed_dataset.shape)\n",
    "\n",
    "\n",
    "# Add perturbation\n",
    "for i in range(3):\n",
    "    perturbed_dataset[:,:,i,i] += eps\n",
    "    \n",
    "print(perturbed_dataset[0,:,0,:])\n",
    "\n",
    "le_dataset = []\n",
    "# Run the dynamics for all perturbations for len_seq steps\n",
    "for state in perturbed_dataset:\n",
    "    ev_dyn0 = np.expand_dims(odeint(f, state[0,0,:], t), axis=1)\n",
    "    ev_dyn1 = np.expand_dims(odeint(f, state[0,1,:], t), axis=1)\n",
    "    ev_dyn2 = np.expand_dims(odeint(f, state[0,2,:], t), axis=1)\n",
    "   \n",
    "    ev_dyn = np.concatenate((ev_dyn0, ev_dyn1), axis=1)\n",
    "    ev_dyn = np.concatenate((ev_dyn, ev_dyn2), axis=1)\n",
    "    le_dataset.append(ev_dyn)\n",
    "\n",
    "# Convert to numpy\n",
    "le_dataset = np.array(le_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29923c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert to tensor\n",
    "l_seq = 20\n",
    "num_sequences = int(4000/l_seq)\n",
    "\n",
    "le_dataset = torch.tensor(le_dataset, requires_grad=True,dtype=torch.float)\n",
    "\n",
    "\n",
    "### Dataloader\n",
    "le_dataloader = DataLoader(le_dataset, batch_size=16, shuffle=True)\n",
    "print(next(iter(le_dataloader)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14133239",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "input_size = 3\n",
    "hidden_units = 10\n",
    "layers_num = 2\n",
    "drop_p = 0.3\n",
    "net_le = LSTM(input_size, hidden_units, layers_num, drop_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e94279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "# Move network to the proper device\n",
    "net_pi.to(device)\n",
    "# Network in training mode (enable stochastic layers, e.g. dropout)\n",
    "net_pi.train()\n",
    "\n",
    "\n",
    "\n",
    "# Create pbar \n",
    "pbar = tqdm(range(num_epochs))\n",
    "\n",
    "for epoch_num in pbar:\n",
    "    epoch_losses = []\n",
    "    \n",
    "    i = 0\n",
    "    for batch_sample in le_dataloader:\n",
    "        \n",
    "        ### Move samples to the proper device\n",
    "        batch_sample = batch_sample.to(device)\n",
    "\n",
    "        ### Prepare network input and labels\n",
    "        net_input  = batch_sample[:, :-1, :]\n",
    "        labels = batch_sample[:, 1:, :]\n",
    "\n",
    "        ### Forward pass\n",
    "        # Clear previous recorded gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        net_out, _ = net_pi(net_input) # we do not need the rnn state at this point, we can ignore the output with \"_\"\n",
    "    \n",
    "        ### Update network\n",
    "        # Evaluate data driven loss\n",
    "        dd_loss = loss_fn(net_out, labels)\n",
    "        # Evaluate physical informed loss\n",
    "        pi_loss = piloss_fn(net_input,net_out)\n",
    "        \n",
    "        loss = beta[i]*dd_loss + pi_loss\n",
    "    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        # Save batch loss\n",
    "        epoch_losses.append(loss.data.cpu().numpy())\n",
    "        \n",
    "        # Update counter\n",
    "        i = i+1\n",
    "        \n",
    "  \n",
    "    # Compute epoch loss\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    \n",
    "    # Set description\n",
    "    pbar.set_description(\"Train loss: %s\" %round(np.mean(epoch_losses),3))\n",
    "    \n",
    "    # Append\n",
    "    log_loss.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48806b73",
   "metadata": {},
   "source": [
    "# Now output in function of the time and initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf29a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
