{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81ea2bf",
   "metadata": {},
   "source": [
    "# Machine Learning Dynamical Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install dependencies\n",
    "!pip install numpy matplotlib scipy\n",
    "!pip install tqdm plotly\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install optuna\n",
    "!pip install pytorch-lightning\n",
    "!pip install google\n",
    "!pip install odeintw\n",
    "!pip install torchdiffeq\n",
    "!pip install sdeint\n",
    "!pip install torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7fbfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "%matplotlib inline\n",
    "\n",
    "# Basic import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.integrate import odeint\n",
    "from odeintw import odeintw\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Pytorch import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset, Subset\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Trainig with lighninig\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping \n",
    "from pytorch_lightning import Callback\n",
    "\n",
    "\n",
    "# Import models\n",
    "from models import LSTM,FFNet, ESN, Transformer\n",
    "from CAE import ConvAE\n",
    "from CLSTMAE import ConvLSTMAE\n",
    "from CVAE import CVAE\n",
    "from ADALSTM import multi_rate_sampler, main\n",
    "from pyESN import ESN\n",
    "#from Informer.model import InformerStack\n",
    "\n",
    "\n",
    "\n",
    "# Import plot functions\n",
    "from plot import gen_trajectory, plot_trajectory, compare_trajectories, plot_3Dtrajectory, poincare_plot, plot_powspec, plot_rec_trajectory, plot_params_distr, plot_3ddistr\n",
    "\n",
    "# Import dataset\n",
    "from dataset import DynSysDataset, GenerateDynSystem\n",
    "\n",
    "# Import callbacks\n",
    "from callbacks import MetricsCallback\n",
    "\n",
    "# Import functions \n",
    "from utils import Lorenz63, Roessler76, Lorenz96, Eul, RK4, CeDLoss, Sampler, nKLDivLoss, R2Score, ENLoss\n",
    "\n",
    "# Import progress bars\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import plotly\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_param_importances, plot_contour\n",
    "\n",
    "\n",
    "#Import sys\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba17acf-f19d-4353-bcde-0d3859e67fd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example of attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd57a10-46e7-461d-8db2-054720099f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = 0.2\n",
    "w = 1\n",
    "def f_harm(u, t):\n",
    "    return u[1], -v*u[1]-w**2*u[0]\n",
    "\n",
    "def f_vp(u,t):\n",
    "    return u[1], (v-u[0]**2)*u[1]-w**2*u[0]\n",
    "\n",
    "u0 = [1,1]\n",
    "time = np.linspace(0,100,1000)\n",
    "us_harm = odeint(f_harm, u0, time)\n",
    "\n",
    "u0 = [0.5,0.5]\n",
    "us_vp = odeint(f_vp, u0, time)\n",
    "u0 = [1,1]\n",
    "us2 = odeint(f_vp, u0, time)\n",
    "\n",
    "# Lorenz63\n",
    "sigma=10\n",
    "rho=28,\n",
    "beta = 8./3.\n",
    "def f_l63(u, t):\n",
    "    return sigma*(u[1]-u[0]), u[0]*(rho-u[2])-u[1], u[0]*u[1]-beta*u[2]\n",
    "\n",
    "u0 = [1,1,1]\n",
    "time = np.linspace(0,40,4000)\n",
    "ldyn = odeint(f_l63, u0, time)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot(ldyn[1000:,0], ldyn[1000:,1], ldyn[1000:,2], c=\"black\")\n",
    "ax._axis3don = False\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"images/l63_attractor.png\")\n",
    "\n",
    "# Roessler 76\n",
    "a=0.37\n",
    "b=0.2\n",
    "c=5.7\n",
    "def f_roess(u,t):\n",
    "    return -u[1]-u[2], u[0]+a*u[1], b+u[2]*(u[0]-c)\n",
    "\n",
    "u0 = [1,1,1]\n",
    "time = np.linspace(0,100,10000)\n",
    "ldyn = odeint(f_roess, u0, time)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot(ldyn[1000:,0], ldyn[1000:,1], ldyn[1000:,2], c=\"black\")\n",
    "ax._axis3don = False\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"images/roess_attractor.png\")\n",
    "\n",
    "a=1.4\n",
    "b=0.3\n",
    "\n",
    "he = [[-0.1,0.1]]\n",
    "for i in range(100000):\n",
    "    x = 1+he[-1][1]-a*he[-1][0]**2\n",
    "    y = b*he[-1][0]\n",
    "    he.append([x,y])\n",
    "    \n",
    "he = np.array(he)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(he[1000:,0], he[1000:,1], c=\"black\", s=0.01)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "# Inset axis\n",
    "axins = ax.inset_axes([0.1, 0.3, 0.4, 0.4])\n",
    "axins.set_xticks([])\n",
    "axins.set_yticks([])\n",
    "axins.set_xlim(0.7, 1)\n",
    "axins.set_ylim(0.12, 0.18)\n",
    "axins.scatter(he[1000:,0], he[1000:,1], c=\"black\", s=0.01)\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "# Inset2\n",
    "axins2 = axins.inset_axes([0.6, 0.6, 0.4, 0.4])\n",
    "axins2.set_xticks([])\n",
    "axins2.set_yticks([])\n",
    "axins2.set_xlim(0.863, 0.9)\n",
    "axins2.set_ylim(0.14, 0.15)\n",
    "axins2.scatter(he[1000:,0], he[1000:,1], c=\"black\", s=0.01)\n",
    "axins.indicate_inset_zoom(axins2, edgecolor=\"black\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"images/henon_attractor.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fccdf2-0ad9-410f-9f66-92f882708c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bb34a-917c-4588-a359-4e593b945e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic map\n",
    "lm = []\n",
    "r_values = np.linspace(2.5,4,1000)\n",
    "for r in r_values:\n",
    "    lm_r = [0.3]\n",
    "    for i in range(1000):\n",
    "        x_new = r*lm_r[-1]*(1-lm_r[-1])\n",
    "        lm_r.append(x_new)\n",
    "\n",
    "    lm.append(lm_r)\n",
    "\n",
    "lm = np.array(lm)\n",
    "print(lm.shape, r_values.shape)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2,figsize=[10, 5])\n",
    "ax[0].set_xlabel(\"r\")\n",
    "ax[0].set_ylabel(\"$x_{\\infty}$\")\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "for xe, ye in zip(r_values, lm[:,100:]):\n",
    "    ax[0].scatter([xe] * len(ye), ye, s=0.001, c=\"black\")\n",
    "\n",
    "# Inset axis\n",
    "axins = ax[0].inset_axes([1.2, 0,1,1])\n",
    "axins.set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "axins.set_xlim(3.5, 4)\n",
    "axins.set_ylim(0, 1)\n",
    "for xe, ye in zip(r_values[667:], lm[667:,100:]):\n",
    "    ax[1].scatter([xe] * len(ye), ye, s=0.001, c=\"black\")\n",
    "    \n",
    "ax[0].indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "# Inset2\n",
    "plt.savefig(\"images/bifurcation_logistic.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016326-edc4-47b5-80e3-04fec29e514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379e13f-43d4-4eb0-8523-0d98c944a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pendolum\n",
    "v = 0.22\n",
    "T = 0.27\n",
    "\n",
    "def f_pend(u,t):\n",
    "    return T*np.sin(u[2])-np.sin(u[1])-v*u[0], u[0], 1.\n",
    "\n",
    "u0 = [0,0,0]\n",
    "time = np.linspace(0,100,100000)\n",
    "pend = odeint(f_pend, u0, time)\n",
    "\n",
    "he = np.array(pend)\n",
    "epsilon=1\n",
    "he[:,2] = he[:,2]%(2*math.pi)\n",
    "he = he[np.logical_and(he[:,2]>-epsilon, he[:,2]<epsilon)]\n",
    "print(he.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ax.scatter(he[:,1], he[:,0], c=\"black\", s=0.01)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"images/henon_attractor.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fde7a-c6f2-4660-9eab-9d1711cbda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2dPhaseDiagram(us, us2=None, filename=None):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    arrow_fmt = dict(markersize=4, color='black', clip_on=False)\n",
    "    arrow_2 = dict(markersize=12, color='black', clip_on=False)\n",
    "    ax.plot(us[:-600,0], us[:-600,1],  c=\"black\")\n",
    "    ax.plot(us[-600:,0], us[-600:,1],  c=\"red\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.annotate(\"A\", (us[0,0]+0.05, us[0,1]))\n",
    "    ax.scatter(us[0,0], us[0,1], s=20,  c=\"black\" )\n",
    "    \n",
    "    if us2 is not None:\n",
    "        ax.scatter(us2[0,0], us2[0,1], s=20,  c=\"black\" )\n",
    "        ax.plot(us2[:-100,0], us2[:-100,1],  c=\"black\")\n",
    "        ax.annotate(\"B\", (us2[0,0]+0.1, us2[0,1]))\n",
    "        ax.plot(us2[-100:,0], us2[-100:,1],  c=\"red\")\n",
    "        \n",
    " \n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlabel('$x^{(1)}$', size=14, labelpad=-24, x=1.03)\n",
    "    ax.set_ylabel('$x^{(2)}$', size=14, labelpad=-21, y=1.02, rotation=0)\n",
    "\n",
    "    \n",
    "    ax.plot((1), (0), marker='>', transform=ax.get_yaxis_transform(), **arrow_fmt)\n",
    "    ax.plot((0), (1), marker='^', transform=ax.get_xaxis_transform(), **arrow_fmt)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "    return fig\n",
    "\n",
    "fig = plot_2dPhaseDiagram(us_harm, filename=\"images/phase_diagram_oscillator.png\")\n",
    "fig = plot_2dPhaseDiagram(us_vp, us2, filename=\"images/phase_diagram_vanderPol.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad68f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51027a35-7c9c-42b2-9a56-930a9b1317d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters and systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2416a7-bd32-4a3d-8f2b-c2c86d4382c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "dt = 0.002\n",
    "train_steps = 100000\n",
    "val_steps = 20000\n",
    "test_steps = 20000\n",
    "seq_len = 100\n",
    "feedforward_steps = 1\n",
    "discard = 1000\n",
    "sigma = None # standard deviation\n",
    "include_time = False\n",
    "convolution = False\n",
    "\n",
    "### Systems\n",
    "## Lorenz63\n",
    "true_params_l63 = np.array((28., 10., 8.0/3.0))\n",
    "true_params_l63 = torch.tensor(true_params_l63, dtype=torch.float32, requires_grad=False)\n",
    "l63 = Lorenz63(params=true_params_l63)\n",
    "l63.params.requires_grad = False\n",
    "\n",
    "## Lorenz96\n",
    "n_dim = 5\n",
    "np.random.seed(0)\n",
    "true_params_l96 = np.array((np.ones(n_dim), np.random.uniform(0.9, 1.1, n_dim), np.random.uniform(7.9, 8.1, n_dim)))\n",
    "true_params_l96 = torch.tensor(true_params_l96, dtype=torch.float32, requires_grad=False)\n",
    "l96 = Lorenz96(dim=n_dim, params=true_params_l96)\n",
    "l96.params.requires_grad = False\n",
    "\n",
    "\n",
    "## Rössler\n",
    "true_params_r76 = (0.37, 0.2, 5.7)\n",
    "true_params_r76 = torch.tensor((0.37, 0.2, 5.7), dtype=torch.float32, requires_grad=False)\n",
    "r76 = Roessler76(params = true_params_r76)\n",
    "r76.params.requires_grad = False\n",
    "\n",
    "# Define system to use and generate data\n",
    "true_system = l63\n",
    "true_params = true_params_l63\n",
    "#true_system.args.requires_grad = False\n",
    "#print(true_system.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64deba8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "state0 = torch.rand(true_system.dim)\n",
    "filename = \"datasets/train_\"+true_system.__class__.__name__+\"_steps\"+str(train_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "train_dataset, t_train = GenerateDynSystem(state0, true_system, dt, train_steps, discard, filename, sigma, include_time)()\n",
    "\n",
    "\n",
    "# Validtion dataset\n",
    "state0 = torch.rand(true_system.dim)\n",
    "filename = \"datasets/val_\"+true_system.__class__.__name__+\"_steps\"+str(val_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "val_dataset, t_val = GenerateDynSystem(state0, true_system, dt, val_steps, discard, filename, sigma, include_time)()\n",
    "\n",
    "# Test dataset\n",
    "state0 = train_dataset[-1]\n",
    "discard_test=0\n",
    "filename = \"datasets/test_\"+true_system.__class__.__name__+\"_steps\"+str(test_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "test_dataset, t_test = GenerateDynSystem(state0, true_system, dt, test_steps, discard_test, filename, sigma, include_time)()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dad684-4922-4aa8-9f81-a9a9431c9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataloaders\n",
    "batch_size = 20\n",
    "train_filename = \"datasets/train_\"+true_system.__class__.__name__+\"_steps\"+str(train_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "\n",
    "train_states = DynSysDataset(train_filename, seq_len=seq_len, discard=discard, dt=dt, tau=1,convolution=convolution)\n",
    "t_train = train_states.time\n",
    "train_dataset = train_states.dataset\n",
    "train_dataloader = DataLoader(train_states, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "val_filename = \"datasets/val_\"+true_system.__class__.__name__+\"_steps\"+str(val_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "val_states = DynSysDataset(train_filename, seq_len=seq_len, discard=discard, dt=dt, tau=1,convolution=convolution)\n",
    "t_val = val_states.time\n",
    "val_dataset = val_states.dataset\n",
    "val_dataloader = DataLoader(val_states, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "test_filename = \"datasets/test_\"+true_system.__class__.__name__+\"_steps\"+str(test_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "test_states = DynSysDataset(test_filename, seq_len=seq_len, discard=discard, dt=dt, tau=1,convolution=convolution)\n",
    "t_test = test_states.time\n",
    "test_dataset = test_states.dataset\n",
    "test_dataloader = DataLoader(test_states, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "### Plot dataset\n",
    "# Train dataset\n",
    "#rk4 = RK4(dt, true_system)\n",
    "#eul = Eul(dt, true_system)\n",
    "#train_dataset = eul(train_dataset)\n",
    "name_dyn_data = \"images/dynamics_\"+true_system.__class__.__name__+\".png\"\n",
    "name_train_attractor = \"images/attractor_\"+true_system.__class__.__name__+\".png\"\n",
    "name_test_attractor = \"images/attractor_test_\"+true_system.__class__.__name__+\".png\"\n",
    "train_dynamics = plot_trajectory(train_dataset, time=t_train, n_var=3, labels=[\"x\",\"y\",\"z\"], filename = name_dyn_data, prediction_steps=10000)\n",
    "train_attractor = plot_3Dtrajectory(train_dataset, filename = name_train_attractor)\n",
    "test_attractor = plot_3Dtrajectory(test_dataset, filename = name_test_attractor)\n",
    "print(test_dataset.shape[0], t_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aa78a-e50d-4833-8ae1-800cb9520a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[-1], test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645605bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db10b05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2bad2d-76bf-4a2c-b440-e49efc86e97b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2299037",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter optmization\n",
    "#Check if the GPU is available\n",
    "\n",
    "\n",
    "# Define annealing\n",
    "max_num_epochs = 2000\n",
    "initial_value = 5\n",
    "exp_decay = np.exp(-np.log(initial_value) / max_num_epochs * 6) # We compute the exponential decay in such a way the shape of the exploration profile does not depend on the number of iterations\n",
    "annealing = [initial_value * (exp_decay ** i) for i in range(max_num_epochs)]\n",
    "    \n",
    "# Define loss function\n",
    "loss_fn = PILoss(dt,field = L63_field(rho = 28.0, sigma = 10.0, beta = 8.0/3.0), annealing= [1]*max_num_epochs)\n",
    "\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define objects to be optimized\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log = True)\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 10,200)\n",
    "    layers_num = trial.suggest_int(\"layers_num\", 2,5)\n",
    "    drop_p = trial.suggest_float(\"dropout\", 0.0, 1.0)\n",
    "   \n",
    "    # Define network\n",
    "    input_size = 3\n",
    "    model = LSTM(input_size, hidden_units, layers_num, drop_p)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "        \n",
    "    # Train\n",
    "    max_num_epochs = 100\n",
    "    early_stopping = False\n",
    "    train_loss, val_loss = pi_train(model, device, train_dataloader, val_dataloader, loss_fn, optimizer, max_num_epochs, early_stopping)\n",
    "    \n",
    "    # Metric to be minimized is the last validation loss\n",
    "    return np.mean(val_loss[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a68691",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials= 20)\n",
    "study.best_params  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b62e05-1bc0-4137-b03b-b56975ca0250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Learning the dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73590a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Initialization\n",
    "max_num_epochs = 100\n",
    "## Annealing\n",
    "# Exponential\n",
    "initial_value = 5\n",
    "exp_decay = np.exp(-np.log(initial_value) / max_num_epochs * 6) # We compute the exponential decay in such a way the shape of the exploration profile does not depend on the number of iterations\n",
    "annealing = [initial_value * (exp_decay ** i) for i in range(max_num_epochs)]\n",
    "# Inverse sigmoid\n",
    "c = 0.01\n",
    "d = 0.5\n",
    "sig_cv = [initial_value*np.exp(-c*(i-max_num_epochs*d))/(1. + np.exp(-c*(i-max_num_epochs*d))) for i in range(max_num_epochs)]\n",
    "plt.plot(sig_cv)\n",
    "\n",
    "\n",
    "# Define input size\n",
    "input_size = 4 if include_time else 3\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 20, mode=\"min\")\n",
    "\n",
    "# Set seed and define network\n",
    "torch.manual_seed(0)\n",
    "params_l96 = torch.tensor((np.ones(n_dim), np.ones(n_dim), 8*np.ones(n_dim)),\n",
    "                         dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "system = Lorenz96(dim=n_dim, params = params_l96)\n",
    "\n",
    "params_l63 = torch.tensor((27.0, 11.0, 9.0/3.0), dtype=torch.float32, requires_grad=True)\n",
    "system = Lorenz63(params=params_l63)\n",
    "#params_r76 = torch.tensor((0.37, 0.2, 5.7), dtype=torch.float32, requires_grad=True)\n",
    "#system = Roessler76(params_r76)\n",
    "system.params.requires_grad = False\n",
    "\n",
    "\n",
    "# Check batch dimension\n",
    "print(next(iter(train_dataloader)).shape)\n",
    "use_pi_loss = True\n",
    "use_dd_loss = False\n",
    "hidden_units = 100\n",
    "layers_num = 2\n",
    "net_pi = LSTM(input_size=system.dim, hidden_units=hidden_units, layers_num=layers_num, system=system, true_system=true_system,\n",
    "              drop_p=0.3, method=\"RK4\",\n",
    "              use_pi_loss=use_pi_loss, use_dd_loss=use_dd_loss)\n",
    "\n",
    "\n",
    "# Print args\n",
    "print(true_system.params)\n",
    "print(system.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a950be-f100-48af-b9e0-800954ba7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"LSTM_pi_Lorenz63_ep2000_h100_ln2_sigmaNone.torch\")\n",
    "net_pi.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "net_pi.set_output(False)\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_pi, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3de6bc-8e1e-4aa6-8022-708e2463026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_system.params)\n",
    "print(system.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f7d8e-81e6-4b5e-96ad-e3d047e69f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Names for savings\n",
    "if use_pi_loss:\n",
    "    type=\"pi\"\n",
    "else:\n",
    "    type=\"dd\"\n",
    "\n",
    "\n",
    "root = net_pi.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_ep\"+str(len(metrics_callback.train_loss_log))+\"_h\"+str(hidden_units)+\"_ln\"+str(layers_num)+\"_sigma\"+str(sigma)\n",
    "root = \"LSTM_pi_Lorenz63_ep2000_h100_ln2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_compare = \"compare_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "delay = 20\n",
    "name_poincare = \"poincare_delay\"+str(delay)+\"_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_le = \"le_\"+\"root\"+\".png\"\n",
    "folder = \"images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb030512-9c3f-41b6-849c-7bcc3d113eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_system.params)\n",
    "print(system.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "ax.semilogy(metrics_callback.params_loss_log, label=\"Args loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(folder+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45bd76-9c28-4f3a-9e69-3488fddb7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n",
    "net_pi.eval()\n",
    "net_pi.set_output(True)\n",
    "net_states = gen_trajectory(net_pi.cpu(), test_dataset[0], dd_mode=False, prediction_steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d85841",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "compare = compare_trajectories(net_states, test_dataset, time=t_test, n_var=3, filename=folder+name_compare, prediction_steps=2000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=folder+name_predict, color=None)\n",
    "print(net_states[1:, 0].size, net_states[:-1,0].size)\n",
    "# Poincare map\n",
    "poincare_plot(torch.tensor(test_dataset), delay=delay, filename=folder+name_poincare, prediction_steps=10000, c1=\"black\")\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=folder+name_powspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_pi.state_dict(),\"trained_models/\"+name_net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436647b3-1294-4ac2-a6e0-724bb7166cc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi rate sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3235e4b3-b3ec-48c0-9d63-a80773479145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized\n",
      "Network initialized\n",
      "Network initialized\n"
     ]
    }
   ],
   "source": [
    "### Multi rate sampler\n",
    "num_lstm = 3\n",
    "tau = np.arange(1,num_lstm+1)\n",
    "length = [99]*num_lstm\n",
    "batch_size = 20\n",
    "# Dataloaders\n",
    "train_filename = \"datasets/train_\"+true_system.__class__.__name__+\"_steps\"+str(train_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "train_mrs = multi_rate_sampler(train_filename, tau, length, dt, batch_size=batch_size, shuffle=True)()\n",
    "val_filename = \"datasets/val_\"+true_system.__class__.__name__+\"_steps\"+str(val_steps)+\"_dt\"+str(dt)+\"_sigma\"+str(sigma)+\".pkl\"\n",
    "val_mrs = multi_rate_sampler(val_filename, tau, length, dt, batch_size=batch_size, shuffle=False)()\n",
    "\n",
    "\n",
    "# Stack lstm\n",
    "use_pi_loss = True\n",
    "use_dd_loss = False\n",
    "hidden_units = 100\n",
    "layers_num = 2\n",
    "\n",
    "stack_lstm = []\n",
    "for i in range(num_lstm):\n",
    "    model = LSTM(input_size=true_system.dim, hidden_units=hidden_units, layers_num=layers_num, system=true_system, \n",
    "                 true_system=true_system, drop_p=0.3, method=\"RK4\", use_pi_loss=use_pi_loss, use_dd_loss=use_dd_loss)\n",
    "    stack_lstm.append(model)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c8ec4a-b986-43cf-9a6f-552f9659e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processes \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstack_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_mrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep Learning/MSc thesis/Physical-Informed-Dynamical-Systems/src/ADALSTM.py:81\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(stack_lstm, train_mrs, val_mrs, max_num_epochs)\u001b[0m\n\u001b[1;32m     79\u001b[0m model \u001b[38;5;241m=\u001b[39m stack_lstm[rank]\n\u001b[1;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mset_output(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 81\u001b[0m p \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mProcess(target\u001b[38;5;241m=\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mfit, args\u001b[38;5;241m=\u001b[39m(model, \u001b[43mtrain_mrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m(), val_mrs[rank]\u001b[38;5;241m.\u001b[39mdetach()))\n\u001b[1;32m     82\u001b[0m p\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     83\u001b[0m processes\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "processes = main(stack_lstm, train_mrs, val_mrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe1a1d-ad56-40f5-a3bb-f686c33ab553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+name_net)\n",
    "ada_lstm.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64888919-4fd7-488c-9cbe-af361aa3b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "ada_lstm.set_return_rnn(False)\n",
    "ada_lstm.set_train_out(False)\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=ada_lstm, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e764c-f732-403b-98ef-729ee1800219",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Names for savings\n",
    "root = ada_lstm.__class__.__name__+\"_numlstm\"+str(num_lstm)+\"_\"+true_system.__class__.__name__+\"_ep\"+str(len(metrics_callback.train_loss_log))+\"_h\"+str(hidden_units)+\"_ln\"+str(layers_num)+\"_sigma\"+str(sigma)\n",
    "#root = \"AdaLSTM_numlstm3_Lorenz63_ep148_h100_ln2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_compare = \"compare_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_le = \"le_\"+\"root\"+\".png\"\n",
    "folder = \"images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f069d-e183-4c5d-8982-ec378627eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "#fig.savefig(folder+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30907551-c2b3-406e-8238-b735f4762732",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n",
    "\n",
    "def gen_mrs_trajectory(net, state0, num_lstm, prediction_steps = 1000):\n",
    "    \" Generate a trajectory of prediction_steps lenght starting from test_dataset[0]. Return np.array\"\n",
    "    state = [state0.unsqueeze(0).unsqueeze(0)]*num_lstm\n",
    "    h0 = torch.zeros(net.layers_num, 1, net.hidden_units)\n",
    "    c0 = torch.zeros(net.layers_num, 1, net.hidden_units)\n",
    "    rnn_state = [(h0, c0)]*num_lstm\n",
    "    net_states = []\n",
    "    net.eval()\n",
    "    \n",
    "    for i in range(prediction_steps):\n",
    "        with torch.no_grad():\n",
    "            # Forward past\n",
    "            state, rnn_state = net(state, rnn_state)\n",
    "            net_states.append(state.squeeze().numpy())\n",
    "            state = [state.unsqueeze(1)]*num_lstm\n",
    "\n",
    "    return torch.tensor(net_states)\n",
    "\n",
    "\n",
    "ada_lstm.set_return_rnn(True)\n",
    "ada_lstm.set_train_out(False)\n",
    "net_states = gen_mrs_trajectory(ada_lstm.cpu(), test_dataset[0], num_lstm, prediction_steps=20000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bc39c-9143-4d68-bf25-c3bc84632e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ada_lstm.attention.data.detach().cpu().numpy())\n",
    "print(ada_lstm.attention.data.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b22a80-c4bf-4608-8df7-27a36e910ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot trajectories\n",
    "# Compare trajectory\n",
    "compare = compare_trajectories(net_states, test_dataset, n_var=3, filename=None, prediction_steps=2000)\n",
    "# Attractor\n",
    "plot_3Dtrajectory(net_states, filename=None, color=None)\n",
    "print(net_states[1:, 0].size, net_states[:-1,0].size)\n",
    "# Poincare map\n",
    "poincare_plot(net_states, torch.tensor(test_dataset), filename=None, prediction_steps=10000)\n",
    "# Power spectrum\n",
    "plot_powspec(net_states, test_dataset, filename=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970d277-36fb-4e4b-82c0-5b53dac61718",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(ada_lstm.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2f463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Autograd time differantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0abc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "state0 = [1.0, 1.0, 1.0]\n",
    "include_time = True\n",
    "train_states = DynSysDataset(state0, f, dt, steps, seq_len, discard, include_time=include_time)\n",
    "t_train = train_states.time\n",
    "train_dataset = train_states.dataset\n",
    "train_dataloader = DataLoader(train_states, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "max_num_epochs = 2000\n",
    "c = 0.01\n",
    "d = 0.5\n",
    "\n",
    "loss_fn = EuDLoss(dt, field = L63_field(rho = 28.0,\n",
    "                sigma = 10.0, beta = 8.0/3.0), include_time=include_time)\n",
    "\n",
    "input_size = 4 if include_time else 3\n",
    "params = {\n",
    "    \"input_size\" : 4,\n",
    "    \"hidden_units\" : 100,\n",
    "    \"layers_num\" : 2,\n",
    "    \"drop_p\" : 0.3,\n",
    "    \"loss_fn\" : loss_fn,\n",
    "    \"lr\" : 0.01,\n",
    "    \"feedforward_steps\" : 1,\n",
    "    \"curriculum_learning\" : None,\n",
    "}\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n",
    "# Set seed and define network\n",
    "torch.manual_seed(0)\n",
    "net_pi = LSTM(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trye torch.autograd\n",
    "batch = next(iter(train_dataloader))\n",
    "net_pi.set_output(False)\n",
    "out = net_pi(batch)\n",
    "# Reshape\n",
    "batch = torch.reshape(batch[0,:100], (100,4))\n",
    "out = torch.reshape(out[0,:100], (100,4))\n",
    "\n",
    "grad_outputs = torch.tensor([[0.,0.,0.,1.]]*100)\n",
    "print(grad_outputs.shape)\n",
    "\n",
    "grad = torch.autograd.grad(out[0], batch[0], grad_outputs=grad_outputs[0], is_grads_batched=False)\n",
    "print(grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edc1f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8fe37-afbb-4887-97b0-38079c8eb62c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e93e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_epochs = 1000\n",
    "\n",
    "loss_fn = EuDLoss(dt, field = L63_field(rho = 28.0,\n",
    "                sigma = 10.0, beta = 8.0/3.0))\n",
    "params_tf = {\n",
    "    \"d_model\" : 3,\n",
    "    \"nhead\" : 3,\n",
    "    \"num_encoder_layers\" : 6,\n",
    "    \"num_decoder_layers\" : 6,\n",
    "    \"dim_feedforward\" :  360,\n",
    "    \"dropout\" : 0.3,\n",
    "    \"activation\" : \"relu\",\n",
    "    \"lr\" : 0.01,\n",
    "    \"loss_fn\" : loss_fn,\n",
    "    \"apply_tgt_mask\" : True,\n",
    "    \"apply_src_mask\" : False,\n",
    "}\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")\n",
    "\n",
    "# Set seed and network\n",
    "torch.manual_seed(0)\n",
    "net_tf = Transformer(params_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trainig\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_num_epochs, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_tf, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "plt.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "plt.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/loss_transformer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "net_dict = { \"state\" : net_pi.state_dict(),\n",
    "            \"parameters\" : params}\n",
    "# Save the state dict to a file\n",
    "torch.save(net_dict,\"trained_models/Transformer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919b56c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Informer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "loss_fn = EuDLoss(dt, field = L63_field(rho = 28.0, sigma = 10.0, beta = 8.0/3.0))\n",
    "\n",
    "# Define the network\n",
    "torch.manual_seed(0)\n",
    "net_inf = InformerStack(enc_in = 3, dec_in = 3, c_out = 3, seq_len = 499, label_len = 499, out_len = 1, \n",
    "                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n",
    "                dropout=0.3, lr=0.001, loss_fn=loss_fn, attn='prob', embed='fixed', freq='h', activation='gelu')\n",
    "\n",
    "# Define the callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 100, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df033a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device and train\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=100, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_inf, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "plt.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "plt.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/loss_informer.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "net_dict = { \"state\" : net_pi.state_dict(),\n",
    "            \"parameters\" : params}\n",
    "# Save the state dict to a file\n",
    "torch.save(net_dict,\"trained_models/Informer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093858-4040-4699-86df-116c9c762a93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2f2fb-e4fc-4477-89e8-199479e28fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define loss function\n",
    "loss_fn = nn.MSELoss() \n",
    "max_num_epochs = 1000\n",
    "\n",
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "net_ae = ConvEncoder(in_channels=(1,16), out_channels=(16,32), kernel_sizes=((100,3), (100,1)), \n",
    "           padding=(0,0),  encoded_space_dim=2, act=nn.ReLU, drop_p=0.3, seq_len=seq_len,\n",
    "                loss_fn=loss_fn, lr=0.001)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 1000, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aad4db-11bf-4dea-ae1b-658166fac37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=max_num_epochs, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_tf, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e91f1a-54ed-4742-86a3-a0d446710886",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "plt.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "plt.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/loss_autoencoder.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc293eab-1af7-4fff-8450-f263151b38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed trajectory\n",
    "enc, rec = net_ae(val_states.data)\n",
    "rec = rec.detach().numpy()\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "for i in range(len(rec)):\n",
    "    ax.plot(rec[i,0,:,0], rec[i,0,:,1], rec[i,0,:,2], c=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132433f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1ec2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a01c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "encoded_space_dim = 3\n",
    "enc_space_reg = \"PI\"\n",
    "beta = 1.0\n",
    "gamma = 0.999\n",
    "lr = 0.1\n",
    "lr_scheduler_name = \"ExponentialLR\" \n",
    "\n",
    "net_ae = ConvAE(in_channels=(1,16,16), out_channels=(16,16,32), kernel_sizes=((5,3), (5,1), (5,1)), \n",
    "           padding=(0,0,0),  encoded_space_dim=encoded_space_dim, act=nn.ReLU, drop_p=0.3, seq_len=seq_len, feedforward_steps=1,\n",
    "                lr=lr, dt=0.01, system_name=\"Lorenz63\",system_dim=3,num_param=len(true_params), enc_space_reg=enc_space_reg,\n",
    "                beta=beta, lr_scheduler_name=lr_scheduler_name, gamma=gamma)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 20, mode=\"min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9534b-9d20-4d0c-80be-2cf2eac5dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"ConvAE_reg_Lorenz63_1500_es10_sigmaNone.torch\")\n",
    "net_ae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e178e-7ad4-4ea1-be5d-fc4d31de7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_ae, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af307b-0943-4f06-a055-91a438c08b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define saving names\n",
    "if enc_space_reg is not None:\n",
    "    type=\"reg\"\n",
    "else:\n",
    "    type=\"unreg\"\n",
    "    \n",
    "root = net_ae.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_\"+str(len(metrics_callback.train_loss_log))+\"_es\"+str(encoded_space_dim)+\"_sigma\"+str(sigma)+\"_\"+lr_scheduler_name+str(gamma)\n",
    "#root = \"ConvAE_reg_Lorenz63_1500_es10_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_rec = \"rec_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_hist = \"hist_\"+root+\".png\"\n",
    "name_distr = \"distr_\"+root+\".png\"\n",
    "\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c730f1f-2a79-479d-9949-9e4672876e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "if enc_space_reg is not None:\n",
    "    ax.semilogy(metrics_callback.train_reg_log, label=\"Train reg loss\")\n",
    "    ax.semilogy(metrics_callback.val_reg_log, label=\"Validation reg loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"images/\"+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42850315-70d7-4875-9586-625206b89f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed traejctory\n",
    "net_ae.eval()\n",
    "enc, rec = net_ae(test_states.data)\n",
    "print(enc[:10,3:4])\n",
    "\n",
    "plot_rec_trajectory(rec, filename=\"images/\"+name_rec)\n",
    "# Plot learned parameters distribution\n",
    "fig1, statistics= plot_params_distr(enc, true_params, bins=20, filename=\"images/\"+name_hist)\n",
    "print(statistics)\n",
    "fig2 = plot_3ddistr(enc, true_params, indeces=[0,1,2],filename=\"images/\"+name_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8fd1a-931c-4014-9c18-a6b160826abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_ae.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b479236-74d2-4259-8a65-4d2f9a49d3b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional LSTM autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff3027-3440-4e59-9dab-b98d2449b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "encoded_space_dim = 3\n",
    "enc_space_reg = \"PI\" # method to compute derivative, if None no regularization applied\n",
    "bd = True # bidirectionality\n",
    "lstm_hu = 100 # hidden units of lstm layers\n",
    "ln = 2 # number of layers of lstm\n",
    "beta= 1.0\n",
    "gamma = 0.99\n",
    "lr = 0.01\n",
    "lr_scheduler_name = \"ExponentialLR\" \n",
    "\n",
    "net_lstmae = ConvLSTMAE(in_channels=(1,16,16), out_channels=(16,16,32), kernel_sizes=((5,3), (5,1), (5,1)), \n",
    "           padding=(0,0,0),  encoded_space_dim=encoded_space_dim, lstm_hidden_units=lstm_hu, bidirectional=bd, layers_num=ln, act=nn.ReLU, drop_p=0.3, seq_len=seq_len, feedforward_steps=1,\n",
    "                lr=lr, dt=dt, system_name=\"Lorenz63\",system_dim=3,num_param=len(true_params), enc_space_reg=enc_space_reg,\n",
    "                       beta=beta, lr_scheduler_name=lr_scheduler_name, gamma=gamma)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 20, mode=\"min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999abaf-d330-401e-bf3a-55378a418899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"ConvLSTMAE_reg_Lorenz63_2500_es10_hu100_nl2_sigmaNone.torch\")\n",
    "net_lstmae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc8e20-2d14-4289-a851-510eb0023bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback, early_stopping], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_lstmae, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da0f58f-26c2-4008-a754-0e23b5135fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define saving names\n",
    "if enc_space_reg is not None:\n",
    "    type=\"reg\"\n",
    "else:\n",
    "    type=\"unreg\"\n",
    "    \n",
    "    \n",
    "root = net_lstmae.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_\"+str(len(metrics_callback.train_loss_log))+\"_es\"+str(encoded_space_dim)+\"_hu\"+str(lstm_hu)+\"_nl\"+str(ln)+\"_sigma\"+str(sigma)+\"_\"+lr_scheduler_name+str(gamma)+\"_beta\"+str(beta)\n",
    "#root = \"ConvLSTMAE_reg_Lorenz63_2500_es10_hu100_nl2_sigmaNone\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_rec = \"rec_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_hist = \"hist_\"+root+\".png\"\n",
    "name_distr = \"distr_\"+root+\".png\"\n",
    "\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e823e3f-c764-453c-8538-aff41f421289",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "if enc_space_reg is not None:\n",
    "    ax.semilogy(metrics_callback.train_reg_log, label=\"Train reg loss\")\n",
    "    ax.semilogy(metrics_callback.val_reg_log, label=\"Validation reg loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"images/\"+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c12d4-f84e-4e6f-be51-30b67be22289",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed traejctory\n",
    "net_lstmae.eval()\n",
    "enc, rec = net_lstmae(test_states.data)\n",
    "print(enc.shape)\n",
    "print(rec.shape)\n",
    "plot_rec_trajectory(rec, filename=\"images/\"+name_rec)\n",
    "# Plot learned parameters distribution\n",
    "fig1, statistics= plot_params_distr(enc, true_params, bins=20, filename=\"images/\"+name_hist)\n",
    "print(statistics)\n",
    "fig2 = plot_3ddistr(enc, true_params, indeces=[0,1,2],filename=\"images/\"+name_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db869440-15b8-415f-b562-a4594f323457",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n",
    "net_lstmae.eval()\n",
    "epsilon = 1\n",
    "new_enc = enc.unsqueeze(1).repeat(1,101,1) \n",
    "noise = torch.randn_like(new_enc)*epsilon\n",
    "perturbed = new_enc + noise\n",
    "perturbed = torch.tensor([0,0,0,0,0,0,0,0,0,0], dtype=torch.float32).unsqueeze(0).unsqueeze(0).repeat(990,101,1)\n",
    "perturbed, rnn = net_lstmae.lstm(perturbed)\n",
    "perturbed = net_lstmae.out(perturbed)\n",
    "\n",
    "plot_rec_trajectory(perturbed.unsqueeze(1))\n",
    "print(perturbed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e70470-0895-4c53-90ab-45f96a8d18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_lstmae.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854016ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Convolutional Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034af7b6-786c-460c-bfe1-d6fcdc2db326",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define network\n",
    "torch.manual_seed(0)\n",
    "encoded_space_dim = 10\n",
    "enc_space_reg = \"PI\"\n",
    "beta = 1.\n",
    "net_vae = CVAE(in_channels=(1,16,16), out_channels=(16,16,32), kernel_sizes=((5,3), (5,1), (5,1)), \n",
    "           padding=(0,0,0),  encoded_space_dim=encoded_space_dim, act=nn.ReLU, drop_p=0.3, seq_len=seq_len, feedforward_steps=1,\n",
    "                lr=0.001, dt=0.01, system_name=\"Lorenz63\",system_dim=3,num_param=len(true_params), enc_space_reg=enc_space_reg,\n",
    "                beta=beta)\n",
    "\n",
    "### Define callbacks\n",
    "metrics_callback =  MetricsCallback()\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 1000, mode=\"min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43387cc-c44b-40d1-8c03-7a6b8c86c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "state_dict = torch.load(\"trained_models/\"+\"CVAE_reg_Lorenz63_1000_es10_sigma5.0.torch\")\n",
    "net_vae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363456a-e094-430c-a8b0-a1c705f270bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set proper device \n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch.shape)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Training\n",
    "trainer = pl.Trainer(max_epochs=1000, callbacks=[metrics_callback], accelerator=\"auto\", log_every_n_steps=1)\n",
    "trainer.fit(model=net_vae, train_dataloaders=train_dataloader, val_dataloaders = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28a7c7-688e-4004-a652-b1531e092c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define saving names\n",
    "if enc_space_reg is not None:\n",
    "    type=\"reg\"\n",
    "else:\n",
    "    type=\"unreg\"\n",
    "    \n",
    "root = net_vae.__class__.__name__+\"_\"+type+\"_\"+true_system.__class__.__name__+\"_\"+str(len(metrics_callback.train_loss_log))+\"_es\"+str(encoded_space_dim)+\"_sigma\"+str(sigma)\n",
    "#root = \"CVAE_reg_Lorenz63_1000_es10_sigma5.0\"\n",
    "name_net = root+\".torch\"\n",
    "name_loss = \"loss_\"+root+\".png\"\n",
    "name_rec = \"rec_\"+root+\".png\"\n",
    "name_predict = \"predict_\"+root+\".png\"\n",
    "name_poincare = \"poincare_\"+root+\".png\"\n",
    "name_powspec = \"powspec_\"+root+\".png\"\n",
    "name_hist = \"hist_\"+root+\".png\"\n",
    "name_noise = \"noise_\"+root+\".png\"\n",
    "name_distr = \"distr_\"+root+\".png\"\n",
    "\n",
    "\n",
    "folder = \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52643d-d729-4341-90a7-55c6ab94e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot losses\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes()\n",
    "ax.semilogy(metrics_callback.train_loss_log, label=\"Train loss\")\n",
    "ax.semilogy(metrics_callback.val_loss_log, label=\"Validation loss\")\n",
    "if enc_space_reg is not None:\n",
    "    ax.semilogy(metrics_callback.train_reg_log, label=\"Train reg loss\")\n",
    "    ax.semilogy(metrics_callback.val_reg_log, label=\"Validation reg loss\")\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"images/\"+name_loss)\n",
    "print(\"trained epochs: \"+str(len(metrics_callback.train_loss_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a68dd4-586a-49e7-800d-4e83fc3953dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot reconstructed traejctory\n",
    "net_vae.eval()\n",
    "enc, mean, logvar, indeces_1, indeces_2, indeces_3 = net_vae.encoder(test_states.data)\n",
    "noise = Sampler()(mean, logvar)\n",
    "rec = net_vae.decoder(enc, noise, indeces_1, indeces_2, indeces_3)\n",
    "print(enc.shape)\n",
    "print(mean.shape, logvar.shape)\n",
    "#print(noise)\n",
    "plot_rec_trajectory(rec, filename=\"images/\"+name_rec)\n",
    "# Plot learned parameters distribution\n",
    "fig1, statistics= plot_params_distr(enc, true_params, bins=20, filename=\"images/\"+name_hist)\n",
    "fig2, statistics_noise= plot_params_distr(torch.cat((mean, logvar), dim=-1), torch.tensor((0,0), dtype=torch.float32, requires_grad=False), bins=20, filename=\"images/\"+name_noise)\n",
    "print(statistics)\n",
    "fig3 = plot_3ddistr(enc, true_params, indeces=[0,1,2],filename=\"images/\"+name_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69edac5-1a15-489a-a9d3-507957044088",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12484781-4e60-42e6-b0c8-264d562f35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save network parameters\n",
    "### Save the network state\n",
    "# The state dictionary includes all the parameters of the network\n",
    "# Save the state dict to a file\n",
    "torch.save(net_vae.state_dict(),\"trained_models/\"+name_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bba6a-0f6e-46b8-8039-f16843419235",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reservoir Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "net_esn = ESN(n_inputs = 3, system=true_system, n_outputs = 3, n_reservoir = 500, timestep=0.002, spectral_radius = 1.2, noise = 0.1, extended_states=True, use_pi_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f461579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reservoir network\n",
    "pred, training_rmse, transient = net_esn.fit(train_dataset[90000:-1,:].detach().numpy(), train_dataset[90001:,:].detach().numpy())\n",
    "\n",
    "net_states = net_esn.predict(200,test_dataset.detach().numpy())\n",
    "print(\"Training rmse: %d\" %training_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_states = np.array(net_states)\n",
    "fig, axs = plt.subplots(figsize=(10,5), ncols=2, nrows=3)\n",
    "gs = axs[1, 1].get_gridspec()\n",
    "predict = 10000\n",
    "index = 0\n",
    "for ax in axs[0:,0]:\n",
    "    ax.set_xlabel(\"t\")\n",
    "    ax.plot(t_test[:predict],net_states[:predict, index], label=\"Predicted\")\n",
    "    ax.plot(t_test[:predict],test_dataset[:predict, index].detach().numpy(), label=\"Actual\")\n",
    "    ax.legend(loc = \"upper right\", fontsize = \"x-small\")\n",
    "    index += 1\n",
    "    \n",
    "axs[0,0].set_ylabel(\"x\")\n",
    "axs[1,0].set_ylabel(\"y\")\n",
    "axs[2,0].set_ylabel(\"z\")\n",
    "\n",
    "# remove the underlying axes\n",
    "for ax in axs[0:, -1]:\n",
    "    ax.remove()\n",
    "    \n",
    "axbig = fig.add_subplot(gs[0:, -1], projection=\"3d\")\n",
    "axbig.set_title(\"Predicted Lorenz attractor\")\n",
    "axbig.plot(net_states[:,0], net_states[:,1], net_states[:,2])\n",
    "axbig.legend()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"resnet_lorenz63\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535c58d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lyapunov exponents prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b55033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize perturbation matrix and Local Lyapunov Exponents list\n",
    "#from scipy.linalg import qr\n",
    "from numpy.linalg import qr\n",
    "import math\n",
    "Q = np.eye(3) # choose identity\n",
    "LLEs = []\n",
    "n_div = 40\n",
    "tau = dt*n_div\n",
    "t = []\n",
    "\n",
    "# Define derivative function\n",
    "def df(M, t, J):\n",
    "    return np.dot(J,M)\n",
    "\n",
    "data = train_dataset #net_states\n",
    "\n",
    "# Loop over dataet, jump every n_time steps\n",
    "for j in range(int(len(data)/n_div)):\n",
    "    # Propagate perturbation\n",
    "    M = np.eye(3)\n",
    "    time = np.linspace(j*tau, (j+1)*tau, n_div)\n",
    "    Jac = true_system.jacobian(data[j*n_div], j*tau) \n",
    "    M = odeintw(df, M, time, args=(Jac,))[-1]\n",
    "    # Propagate perturbation\n",
    "    V = np.matmul(M,Q)\n",
    "    # QR decomposition\n",
    "    Q, R = qr(V)\n",
    "    # Adjust sign\n",
    "    sign = np.sign(np.diag(R))\n",
    "    R = np.matmul(np.diag(sign), R)\n",
    "    Q = np.matmul(Q, np.diag(sign))\n",
    "    check_qr = np.allclose(V, np.dot(Q, R))\n",
    "    # Compute local lyapunov exponents\n",
    "    lles = np.log(np.diag(R))/tau\n",
    "    # Append\n",
    "    #print(P)\n",
    "    LLEs = LLEs + [lles]\n",
    "    t.append(j*tau)\n",
    "    \n",
    "LLEs = torch.tensor(LLEs)\n",
    "t = torch.tensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dfe76-81db-49f3-879b-23115dc46c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LLEs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(LLEs[:,0]))\n",
    "discard = 2400\n",
    "lle_fig = plot_trajectory(LLEs[discard:], time=t[discard:], prediction_steps=2000, labels=[\"LLE1\", \"LLE2\", \"LLE3\"])\n",
    "#lle1_attractor = plot_3Dtrajectory(data[discard:], color=LLEs[discard:,0])\n",
    "#lle2_attractor = plot_3Dtrajectory(data[discard:], color=LLEs[discard:,1])\n",
    "#lle3_attractor = plot_3Dtrajectory(data[discard:], color=LLEs[discard:,2])\n",
    "true_le = np.array([0.905, 0.001975, -14.571])\n",
    "fig1, statistics= plot_params_distr(LLEs[discard:], true_le, bins=20, filename=None)\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f213a-2df5-47a9-be7f-76dbfaf9c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset generation\n",
    "\n",
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8.0 / 3.0\n",
    "dt = 0.01\n",
    "\n",
    "eps = 0.01 # Perturbation\n",
    "len_seq = 5 # Length of the pertubed sequence\n",
    "t = np.arange(0.0, dt*len_seq, dt) # Time array\n",
    "\n",
    "# Add pertubation dimension and dynamics dimension\n",
    "print(states_dataset.shape) \n",
    "pd = np.expand_dims(states_dataset, axis=1)\n",
    "pd = np.expand_dims(pd, axis=1)\n",
    "perturbed_dataset = np.concatenate((pd, pd), axis=2)\n",
    "perturbed_dataset = np.concatenate((perturbed_dataset, pd), axis=2)\n",
    "print(perturbed_dataset.shape)\n",
    "\n",
    "\n",
    "# Add perturbation\n",
    "for i in range(3):\n",
    "    perturbed_dataset[:,:,i,i] += eps\n",
    "    \n",
    "print(perturbed_dataset[0,:,0,:])\n",
    "\n",
    "le_dataset = []\n",
    "# Run the dynamics for all perturbations for len_seq steps\n",
    "for state in perturbed_dataset:\n",
    "    ev_dyn0 = np.expand_dims(odeint(f, state[0,0,:], t), axis=1)\n",
    "    ev_dyn1 = np.expand_dims(odeint(f, state[0,1,:], t), axis=1)\n",
    "    ev_dyn2 = np.expand_dims(odeint(f, state[0,2,:], t), axis=1)\n",
    "   \n",
    "    ev_dyn = np.concatenate((ev_dyn0, ev_dyn1), axis=1)\n",
    "    ev_dyn = np.concatenate((ev_dyn, ev_dyn2), axis=1)\n",
    "    le_dataset.append(ev_dyn)\n",
    "\n",
    "# Convert to numpy\n",
    "le_dataset = np.array(le_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29923c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert to tensor\n",
    "l_seq = 20\n",
    "num_sequences = int(4000/l_seq)\n",
    "\n",
    "le_dataset = torch.tensor(le_dataset, requires_grad=True,dtype=torch.float)\n",
    "\n",
    "\n",
    "### Dataloader\n",
    "le_dataloader = DataLoader(le_dataset, batch_size=16, shuffle=True)\n",
    "print(next(iter(le_dataloader)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14133239",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "input_size = 3\n",
    "hidden_units = 10\n",
    "layers_num = 2\n",
    "drop_p = 0.3\n",
    "net_le = LSTM(input_size, hidden_units, layers_num, drop_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e94279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "# Move network to the proper device\n",
    "net_pi.to(device)\n",
    "# Network in training mode (enable stochastic layers, e.g. dropout)\n",
    "net_pi.train()\n",
    "\n",
    "\n",
    "\n",
    "# Create pbar \n",
    "pbar = tqdm(range(num_epochs))\n",
    "\n",
    "for epoch_num in pbar:\n",
    "    epoch_losses = []\n",
    "    \n",
    "    i = 0\n",
    "    for batch_sample in le_dataloader:\n",
    "        \n",
    "        ### Move samples to the proper device\n",
    "        batch_sample = batch_sample.to(device)\n",
    "\n",
    "        ### Prepare network input and labels\n",
    "        net_input  = batch_sample[:, :-1, :]\n",
    "        labels = batch_sample[:, 1:, :]\n",
    "\n",
    "        ### Forward pass\n",
    "        # Clear previous recorded gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        net_out, _ = net_pi(net_input) # we do not need the rnn state at this point, we can ignore the output with \"_\"\n",
    "    \n",
    "        ### Update network\n",
    "        # Evaluate data driven loss\n",
    "        dd_loss = loss_fn(net_out, labels)\n",
    "        # Evaluate physical informed loss\n",
    "        pi_loss = piloss_fn(net_input,net_out)\n",
    "        \n",
    "        loss = beta[i]*dd_loss + pi_loss\n",
    "    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update\n",
    "        optimizer.step()\n",
    "        # Save batch loss\n",
    "        epoch_losses.append(loss.data.cpu().numpy())\n",
    "        \n",
    "        # Update counter\n",
    "        i = i+1\n",
    "        \n",
    "  \n",
    "    # Compute epoch loss\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    \n",
    "    # Set description\n",
    "    pbar.set_description(\"Train loss: %s\" %round(np.mean(epoch_losses),3))\n",
    "    \n",
    "    # Append\n",
    "    log_loss.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48806b73",
   "metadata": {},
   "source": [
    "# Now output in function of the time and initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf29a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
